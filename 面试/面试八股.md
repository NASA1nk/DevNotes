# Java

## static

**静态**修饰符

- **静态变量**（类变量）

  - **对于所在类而言内存中的这个静态变量只存在一个，当且仅当在类初次加载时会被初始化，被类的所有对象共享**
  - 普通的变量在每个对象中都有一份自己的拷贝

- **静态方法**（类方法）

  - 没有`this`参数的方法
  - **跟类一起加载，用类名调用，不能调用非静态的变量和方法**
    - 可以在没有创建任何对象的前提下仅仅通过类本身来调用`static`方法（实际上这正是`static`方法的主要用途）
    - **非静态方法可以调用静态方法和变量**

  - 静态方法可以访问自身类中的静态域

  > `main()`方法就是一个静态方法
  >
  > `Arrays`类中的方法都是`static`修饰的静态方法，可以直接使用`Arrays`类名调用

- **静态代码块**

  - **类一加载就直接执行，且只执行一次**，只有**实例化第一个对象**的时候会调用，后面不会再执行

  > **执行先后顺序**
  >
  > 1. 静态代码块
  > 2. 匿名代码块
  > 3. 构造器

## final

`final`关键字可以用来修饰类、方法和变量（包括成员变量和局部变量）

**final修饰类**

- 当用`final`修饰一个类时，表明**这个类不能被继承**
- `final`类中的**成员变量可以根据需要设为`final`**
- `final`类中的**所有成员方法都会被隐式地指定为`final`方法**

**final修饰方法**

- 如果想明确**禁止该方法在子类中被覆盖**的情况下才将方法设置为`final`
- 类的`private`方法会隐式地被指定为`final`方法

> 使用`final`方法的原因有两个
>
> - 第一个原因是把方法锁定，以防任何继承类修改它的含义
> - 第二个原因是效率，在早期的Java实现版本中，会将`final`方法转为**内嵌调用**，但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升
>
> 最近的Java版本中，不需要使用`final`方法进行这些优化了

**final修饰变量**

- 对于一个`final`变量，如果是基本数据类型，其数值一旦在初始化之后便不能更改，如果是**引用类型的变量，在对其初始化之后不能再让其指向另一个对象**，但**引用指向的对象的内容是可变的**

### 类的final变量和普通变量有什么区别？

- `final`修饰的类的成员变量**必须在定义时或者构造器中进行初始化赋值**，而且一旦被初始化赋值之后就不能再被赋值了
  - 注意是类的成员变量，局部变量只需要保证在使用之前被初始化赋值即可
- 当`final`变量是基本数据类型和`String`类型时，如果**在编译期间能知道它的确切值则编译器会把它当做编译期常量使用**，在用到该`final`变量的地方，相当于直接访问的这个常量，不需要在运行时确定
  - 只有在编译期间能确切知道`final`变量值的情况下，编译器才会进行这样的优化

### final和static的区别

- `static`关键字作用于成员变量用来**表示只保存一份副本**，而`final`关键字的作用是用来保证**变量不可变**


## 多态

多态性是面向对象编程的一个重要特征，又叫**动态绑定**（dynamic binding）

- 它是指在**父类中定义的属性和方法被子类继承之后，可以具有不同的数据类型或表现出不同的行为**，这使得同一个属性或方法在父类及其各个子类中具有不同的含义
  - 即一个对象变量可以指示多种实际类型，同一个方法根据对象的不同而采取不同的行为方式
- 在Java中**对象变量是多态的，一个对象的实际类型是确定的，但是可以指向对象的引用类型有很多**
  - 可以将**子类对象赋给父类引用**，但不能将父类对象赋给子类引用
- 无法重写的方法无法实现多态
  - `static`，`final`，`private`修饰的方法都不可以（`private`方法会隐式地被指定为`final`方法）

### 编译时多态和运行时多态

多态分为**编译时多态**和**运行时多态**

- 编译时多态是静态的，主要是指**方法的重载**，它是**根据参数列表的不同来区分不同的方法**，通过编译之后会变成两个不同的方法，在运行时谈不上多态
- 运行时多态是动态的，它是**通过动态绑定来实现**的，也就是通常说的多态性

### 动态绑定

- **在运行期间判断所引用的对象的实际类型**，根据其实际的类型调用其相应的方法
- 父类引用指向子类对象，但是父类引用所能看到的只属于父类那部分属性和方法，所以此过程还存在指针指向变化情况（因为重写），从指向原来自己方法变化到指向`new`出来的对象的方法


Java实现多态有**3个必要条件**

- **继承**
- **重写**
  - 子类对父类中某些方法进行重新定义，在调用这些方法时就会调用子类的方法
- **父类引用指向子类对象**
  - 向上转型
  - 只有这样该引用**才既可以调用父类的方法，又可以调用子类的方法**

只有满足这3个条件，才能够在同一个继承结构中**使用统一的逻辑实现代码处理不同的对象，从而执行不同的行为**

## 重载和重写
### 重载

`@Overload`  

- 指一个类中允许存在多个同名方法，这些方法的**参数表不同（参数个数或者参数类型不同）**

### 重写

`@Override`

- 指两个方法具有相同的方法名称和参数，分别位于父类和子类中，重写允许**子类提供已经提供其父类的方法的特定实现**

### 规则

**重载**

- 被重载的方法**必须改变参数列表**（参数个数或类型或顺序不一样）
- 被重载的方法可以改变返回类型
- 被重载的方法可以改变访问修饰符
- 被重载的方法可以声明新的或更广的检查异常
- 方法能够在同一个类中或者在一个子类中被重载
- **无法以返回值类型作为重载函数的区分标准**

**重写**

- 参数列表必须完全与被重写方法的相同
- **返回类型必须完全与被重写方法的返回类型相同**
- 访问权限不能比父类中被重写的方法的访问权限更低
  - 如果父类的一个方法被声明为`public`，那么在子类中重写该方法就不能声明为protected
- 父类的成员方法只能被它的子类重写
- 声明为`final`的方法不能被重写
- 声明为`static`的方法不能被重写，但是能够被再次声明
- 子类和父类在同一个包中，那么子类可以重写父类所有方法，除了声明为`private`和`final`的方法
- 子类和父类不在同一个包中，那么子类只能够重写父类的声明为`public`和`protected`的非`final`方法
- 重写的方法能够抛出任何非强制异常，无论被重写的方法是否抛出异常
  - 但是重写的方法不能抛出新的强制性异常，或者比被重写方法声明的更广泛的强制性异常，反之则可以
- **构造方法不能被重写**
- **如果不能继承一个方法，则不能重写这个方法**

**虚拟机分派**

- **重载**：在编译阶段，虚拟机会根据**参数的静态类型**决定使用哪个重载版本（方法在实际运行时内存中的入口地址），即**静态分派**
- **重写**：当子类重新定义了父类的方法实现后，**父类指针根据赋给它的不同的子类指针，动态的调用属于子类的该函数**，在运行时根据子类（实际类型）确定方法的执行版本（方法在实际运行时内存中的入口地址），即**动态分派**

## 抽象类和接口

- **接口只有定义，不能有方法的实现，抽象类可以有定义与实现，方法可在抽象类中实现**
  - Java1.8中接口可以定义`default`方法体
- 实现接口的关键字为`implements`，继承抽象类的关键字为`extends`
  - **Java不能多继承，一个类只能继承一个抽象类，但可以实现多个接口，实现多个接口可以间接地实现多重继承**
- **接口强调特定功能的实现，而抽象类强调所属关系**
  - 实现接口是一种LIKE-A的关系，继承抽象类是一种IS-A的关系
- **抽象类定义基本的共性内容，接口是定义额外的功能**
  - 继承抽象类可以实现对父类代码的复用，也可以重写抽象方法实现子类特有的功能，实现接口可以为类新增额外的功能
- 接口成员变量默认为`public static final`，**必须赋初值，不能被修改**，其所有的成员方法都是`public`，`abstract`的，抽象类中成员变量默认`default`，**可在子类中被重新定义，也可被重新赋值**，抽象方法被`abstract`修饰，不能被`private`，`static`，`synchronized`和`native`等修饰，必须以分号结尾，不带花括号

> 使用动机不同，实现接口是为了使用它规范的某一个行为，继承抽象类是为了使用这个类属性和行为

## String

**Java中所有的字符串的字面值都是`String`类的一个实例**

- `String`是一个`final`类，它无法被继承
- `String`对象的字符内容存储在一个`final`修饰的字符数组`value[]`中，所以不可变
- `String`实现了`Serializable`接口，表示字符串是**可以序列化的**
- `String`实现了`Comparable`接口，表示字符串是**可以比较大小的**
- **字符串是常量，创建后不能更改**，当对字符串**重新赋值，拼接和替换**时，需要重新指定内存区域

> 方法区中包含字符串常量池，常量池不会存储相同内容的字符串

### 字符串的存储位置

**直接赋值**

- 字符串字面值会被存储在**常量池**中，只有1个（全局共享），此时的赋值操作等于是**创建0个或1个对象**
  - 如果常量池中已经存在字面值，那么不会再创建对象，直接将引用赋值
  - 如果常量池中没有字面值，那么创建一个对象，并将引用赋值


`new String()`

- 此时的赋值操作等于是**创建1个或2个对象**
  - 先检索常量池中是否存在字面值，如果不存在字面值，则会先在常量池中创建字面值
  - 然后再执行`new`操作，**在堆中创建一个存储字面值的`String`对象，并将对象的引用赋值**

> 即`new`一定会创建对象


### String，StringBuffer，StringBuilder

**效率**：`StringBuilder` > `StringBuffer` > `String`

`StringBuilder`类

- **可变的字符序列**
  - 字符存储在一个`char`数组中，没有`final`修饰，可变
- **线程不安全的，效率高**

`StringBuffer`类

- **可变的字符序列**
  - 字符存储在一个`char`数组中，没有`final`修饰，可变
- **线程安全的，效率低**

## Arrays.sort

- `Arrays.sort()`可以排序**基本对象类型**，但是**不可以使用基本数据类型**
  - 基本数据类型需要转化（自动装箱）为对应的对象类型

> 数组不能自动装箱

### 双轴快排

DualPivotQuicksort

- 快排使用一个元素作为轴（pivot），通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比轴元素小，另外一部分的所有数据都比轴元素大
- **双轴快排则是有两个轴元素pivot1和pivot2**，且`pivot ≤ pivot2`
  - 将待排序序列分成三段：`x < pivot1`，`pivot1 ≤ x ≤ pivot2`和`x > pivot2`，然后分别对三段进行递归

> 这个算法通常会比传统的快排效率更高

**JDK1.8**

1. 判断数组的长度是否大于286，**大于则使用归并排序**
2. 判断数组长度是否小于47，**小于则直接采用插入排序**
3. 用公式`length/8+length/64+1`近似计算出**数组长度的1/7**，再根据经验**取5个等距点**，将这5个元素进行插入排序
4. 选取**第二个位置**和**第四个位置**的元素（`a[e2]`，`a[e4]`）分别作为`pivot1`和`pivot2`
   1. 因为步骤3进行了排序，所以一定有`pivot1 <= pivot2`

5. 根据`pivot1`和`pivot2`**将整个数组分为四部分**，在最开始比较前，除了轴点其余元素几乎都在第四部分，**直到比较完之后第四部分没有元素**
   1. 第一部分：比`pivot1`小的元素
   2. 第二部分：比`pivot1`大比`pivot2`小的元素
   3. 第三部分：比`pivot2`大的元素
   4. 第四部分：尚未比较的部分

6. 定义两个指针`less`和`great`，`less`从最左边开始向右遍历，一直找到第一个不小于`pivot1`的元素，`great`从右边开始向左遍历，一直找到第一个不大于`pivot2`的元素
7. 定义指针`k`从`less-1`开始向右遍历至`great`，把小于`pivot1`的元素移动到`less`左边，大于`pivot2`的元素移动到`great`右边
   1. 虽然`great`处的元素小于`pivot2`，但是它和`pivot1`的大小关系还需要进行判断，如果比`pivot1`还小，就需要移动到到`less`左边，否则只需要交换到`k`处

8. 将`less-1`处的元素移动到队头，`great+1`处的元素移动到队尾，并把`pivot1`和`pivot2`分别放到`less-1`和`great+1`处
9. 则`less`左边的元素都小于`pivot1`，`great`右边的元素都大于`pivot2`，分别对两部分进行同样的递归排序
10. 对于中间的部分，如果大于4/7的数组长度，**很可能是因为重复元素的存在**，所以把`less`向右移动到第一个不等于`pivot1`的地方，把`great`向左移动到第一个不等于`pivot2`的地方，然后再对`less`和`great`之间的部分进行递归排序

```java
/*
 * Partitioning:
 *
 *   left part           center part                   right part
 * +--------------------------------------------------------------+
 * |  < pivot1  |  pivot1 <= && <= pivot2  |    ?    |  > pivot2  |
 * +--------------------------------------------------------------+
 *               ^                          ^       ^
 *               |                          |       |
 *              less                        k     great
 *
 * Invariants:
 *
 *              all in (left, less)   < pivot1
 *    pivot1 <= all in [less, k)     <= pivot2
 *              all in (great, right) > pivot2
 *
 * Pointer k is the first index of ?-part.
 */
        outer:
        for (int k = less - 1; ++k <= great; ) {
            int ak = a[k];
            if (ak < pivot1) { // Move a[k] to left part
                a[k] = a[less];
                /*
                 * Here and below we use "a[i] = b; i++;" instead
                 * of "a[i++] = b;" due to performance issue.
                 */
                a[less] = ak;
                ++less;
            } else if (ak > pivot2) { // Move a[k] to right part
                while (a[great] > pivot2) {
                    if (great-- == k) {
                        break outer;
                    }
                }
                if (a[great] < pivot1) { // a[great] <= pivot2
                    a[k] = a[less];
                    a[less] = a[great];
                    ++less;
                } else { // pivot1 <= a[great] <= pivot2
                    a[k] = a[great];
                }
                /*
                 * Here and below we use "a[i] = b; i--;" instead
                 * of "a[i--] = b;" due to performance issue.
                 */
                a[great] = ak;
                --great;
            }
        }

```

## 序列化

### Java中如果有些字段不想进行序列化，怎么处理？

对于不想进行序列化的变量，使用`transient`关键字修饰

- `transient`只能修饰变量，不能修饰类和方法
- `transient`可以阻止实例中那些用`transient`修饰的的变量序列化
- 当对象被反序列化时，被`transient`修饰的变量值不会被持久化和恢复

## ==和equals()的区别

`==`

- 对于基本类型，比较**值是否相等**

- 对于对象，比较的是两个**对象的地址是否相同，即是否是指相同一个对象**

`equals()`

- 默认实现使用`==`来比较两个对象是否相等（即比较地址）
- **但是像`Integer`、`String`这些类对`equals()`方法进行了重写，比较的还是两个对象的内容（值）是否相等**

**注意**

- 对于`Integer`，如果依然坚持使用`==`来比较，对于`[-128,127]`区间里的数，会有一个缓存，所以会值相同也会返回相等

- 对于`String`，它也有一个常量池

```java
Integer a = 127;
Integer b = 127;
// true，使用了缓存
System.out.println(a == b); 

Integer a = 128;
Integer b = 128;
// false，不使用缓存，比较地址
System.out.println(a == b); 

// new，则对象a在堆中
Integer a = new Integer(127);
Integer b = 127;
// false
System.out.println(a == b);

=====================================================

String a = "gg" + "rr";
String b = "ggrr";
// true
System.out.println(a == b); 

// b在堆上创建，因为已经存在a字面值，所以直接指向a
String a = "gg" + "rr";
String b = new String("ggrr");
// true
System.out.println(a == b);
```

## 实现不可变对象的策略

比如JDK中的`String`类

- 不提供`setter()`方法
  - 包括修改字段、字段引用到的的对象等方法
- 将所有字段设置为`final`、`private`
- 将类修饰为`final`，不允许子类继承、重写方法
- 可以将构造函数设为`private`，**通过工厂方法创建**
- 如果类的字段是对可变对象的引用，不允许修改被引用对象
  - 不提供修改可变对象的方法
  - 不共享对可变对象的引用
  - 对于外部传入的可变对象，不保存该引用，**如要保存，可以保存其复制后的副本**
  - 对于内部可变对象，不要返回对象本身，**而是返回其复制后的副本**

## native方法

`native`关键字修饰

- 说明这个方法是个原生函数，不是用Java语言实现的，是使用C/C++实现的
- 被编译成了**动态链接库（Dynamic Link Library，DLL）**，由Java去调用，JDK源码中不包含
- 对于不同的平台它们是不同的，Java在不同的操作系统中调用不同的`native`方法实现对操作系统的访问
  - 因为Java没有指针，不能直接访问操作系统底层

> DLL是Windows系统中**封装代码和数据以及实现资源共享**的一种方式，本质上就是一个已经编译好的机器指令文件
>
> 动态链接是指程序运行时有需要才去调用某个DLL库，一个DLL库中会包含各种函数并对外提供API

**调用过程**

1. 在java中声明`native`方法，然后编译
2. 用`javah`产生一个 `.h` 文件
3. 写一个 `.cpp`文件实现`native`方法
   1. 需要包含第二步产生的`.h`文件
   2. 需要包含了jdk带的jni.h文件
4. 将`.cpp`文件编译成动态链接库文件
5. 在java中用`System.loadLibrary()`文件加载动态链接库文件

这个`navite`方法就可被访问了

## 集合

- **集合只能存放对象的引用**，添加基本数据类型会被**自动装箱**后存入集合

- `Collection`和`Map`是平级的，`Map`没有实现`Collection`

### ArrayList的优缺点

`ArrayList`底层以数组实现，比较适合**顺序添加、随机访问**的场景

**优点**

- `ArrayList`实现了`RandomAccess`接口，支持随机访问，速度非常快
- `ArrayList`在顺序添加一个元素的时候非常方便

**缺点**

- `ArrayList`在删除和插入元素的时候，**需要做一次元素复制操作**，如果要复制的元素很多，那么就会比较耗费性能

### ArrayList和LinkedList的区别

> `ArrayList` 和 `LinkedList`都是线程不安全的

- `ArrayList`的实现基于**数组**，`LinkedList`的实现基于**双向链表**
- 对于**随机访问**，`ArrayList`优于`LinkedList`
  - `ArrayList`可以根据下标以`o(1)`时间复杂度对元素进行随机访问，而`LinkedList`的每一个元素都依靠地址指针和它后一个元素相连接，查找某个元素的时间复杂度是`o(n)` 
- 对于**插入和删除**操作，`LinkedList`优于`ArrayList`
  - 元素被添加到`LinkedList`任意位置的时候，不需要像`ArrayList`那样重新计算大小或者是更新索引
  - `ArrayList`的插入和删除受元素位置的影响，执行`add(E e)  `时， `ArrayList`会默认**将指定的元素追加到列表的末尾**，此时，时间复杂度是`o(1)`，执行`add(int index, E e) `时，时间复杂度就是`o(n)`
- `LinkedList`比`ArrayList`更占内存，因为`LinkedList`的节点除了存储数据，**还存储了两个引用**，一个指向前一个元素，一个指向后一个元素
  - `ArrayList`的空间浪费主要体现在在结尾会预留一定的容量空间


### LinkedList为什么用双向链表不用单向链表

**删除**

- 删除单链表中的某个结点时，一定要得到待删除结点的前驱，得到前驱节点有两种方法

  - 第一种方法是在**定位待删除结点的同时一路保存当前结点的前驱**


  - 第二种方法是在定位到待删除结点之后，**重新从单链表表头开始来定位前驱**


- 如果用双向链表，则不需要定位前驱结点，因此指针总的移动操作是`i`次

> 尽管通常会采用方法一，但其实这两种方法的效率是一样的，指针的总的移动操作都是`2*i`次

**查找**

- 可以借用二分法的思路，从`head`头节点向后查找操作和从`tail`尾节点向前查找操作同步进行，**这样双链表的效率可以提高一倍**

### HashSet实现原理

`HashSet`是基于`HashMap`实现的，**默认构造函数是构建一个初始容量为16，负载因子为0.75的`HashMap`**

- `HashSet`底层封装了一个`HashMap`对象来存储所有的集合元素，**所有放入`HashSet`中的元素实际上由`HashMap`的`key`来保存**
  - `HashMap`对象的`value`则存储了一个`PRESENT`（一个静态的`Object`对象）
  - `HashSet`的其他操作也都是基于`HashMap`的，直接调用底层`HashMap`的相关方法
- 一个类的对象作为`HashMap`的`key`，或将这个类的对象存入`HashSet`中时，**需要重写该类的`equals()`方法和`hashCode()`方法**，并且这两个方法的返回值必须保持一致

> `HashSet`实现了`Set`接口，`HashMap`实现了`Map`接口

#### 重写hashCode()和equals()

`Collection`接口：对象所在类需要重写`equals()`方法

- `contains(Object obj)`：调用对象所在类的`equals`方法来判断集合中每一个元素是否是目标元素
- `remove(Object obj)` ：调用对象所在类的`equals`方法判断是否是要删除的那个元素，**只会删除匹配的第一个元素**

`Set`接口：对象所在类要重写`equals()`和`hashCode()`方法，以实现**对象相等规则**

- **相等的对象必须具有相等的散列码**

> `Map`中的`key`使用`Set`存储，所以`key`所在类必须重写`hashCode()`和`equals()`方法

**重写hashCode()规则**

- 对同一个对象多次调用`hashCode()`方法应该返回相同的hashCode值
- 当两个对象的`equals()`方法比较返回`true`时，两个对象的`hashCode()`方法的返回值也应相等
- **对象中用作`equals()`方法比较的属性，都应该用来计算`hashCode()`的返回值**
  - 所以重写了`equals()`方法也要重写`hashCode()`方法

> IDEA中在自定义类调用工具自动重写`equals()`和`hashCode()`方法时默认使用31
>
> - 31只占用5bits，相乘造成数据溢出的概率较小
> - 31可以由`i*31== (i<<5)-1`来表示，现在很多虚拟机里面都有做相关优化（提高算法效率）
> - 31是一个素数，一个数字乘以素数的最终结果只能被素数本身和被乘数还有1来整除（减少冲突）
> - 选择系数的时候要选择尽量大的系数，因为计算出来的hash地址越大，冲突就越少，查找起来效率也会提高

#### hashcode()找位置，equals()判断位置上的元素

1. `HashSet`会调用要添加**对象的所在类**的`hashCode()`方法来得到该对象的hashCode值
2. 散列函数根据对象的`hashCode()`返回值（对象的hashCode值）决定它在`HashSet`底层数组中的**存储位置**
   1. 散列函数会利用**底层数组的长度**计算得到对象在数组中的下标
   2. **散列函数计算会尽可能保证能均匀存储**，越是散列分布，该散列函数设计的越好
3. 如果该存储位置上**没有其他对象，则添加该对象**
4. 如果该存储位置上有其他对象，由于**不同的hashCode值可能映射到同一个位置**，则需要比较两个对象的hashCode值
   1. 如果两个对象的**hashCode值不相等，则通过链表的方式添加该对象**
   2. 如果两个对象的**hashCode值相等，再调用`equals()`方法判断对象是否相同**
      1. 如果`equals()`方法结果为`true`，则添加失败（如果是`HashMap`则是直接覆盖）
      2. 如果`equals()`方法结果为`false`，**则通过链表的方式添加该对象**

以链表的形式在同一个位置上存放多个元素会使得`HashSet`的性能降低，**因为不能快速定位了**

### HashMap为什么不直接使用hashCode()方法

- 原始的`hashCode()`方法返回的是**int整数类型**，其范围为`-(2^31)~(2^31 - 1)`，**约有40亿个映射空间**

- `HashMap`的容量范围是在`16~2^30`，通常情况下是取不到最大值的，并且设备上也难以提供这么多的存储空间，从而导致通过`hashCode()`计算出的哈希值可能不在数组大小范围内，进而无法匹配存储位置

所以`HashMap`实现了自己的`hash()`方法

- 通过**两次扰动**使得它自己的哈希值高低位自行进行异或运算，**降低哈希碰撞概率也使得数据分布更平均**
  - 扰动函数指的就是`HashMap`的`hash()`方法，使用扰动函数是为了**防止一些实现比较差的`hashCode()`方法**导致碰撞率变大， 即使用扰动函数之后可以减少碰撞

- 在保证**数组长度为2的幂次方**的时候，使用`hash()`运算之后的值通过`&`运算来获取数组下标的方式进行存储
  - 比取余操作更加有效率
  - 只有当数组长度为2的幂次方时，`hash&(length-1)`才等价于`hash%length`
  - 解决了哈希值与数组大小范围不匹配问题

> `String`和`Integer`等包装类的特性能够保证Hash值的不可更改性和计算准确性，能够有效的减少Hash碰撞的几率
>
> - 都是`final`修饰的类，不可变性保证key的不可更改性
> - 内部已重写了`equals()`、`hashCode()`等方法

### HashMap 的长度为什么是2的幂次方

为了能让`HashMap`**存取高效，尽量较少碰撞**，也就是要尽量把数据分配均匀

- 上面说了`hash`值的范围值-2147483648~2147483648，加起来大概40亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的，但问题是**一个40亿长度的数组，内存是放不下的，所以这个hash值不能直接拿来用，在用之前要先做对数组的长度取模运算**，`hash%length`得到的余数才是要存放的位置，即对应的数组下标
- 使用`&`操作相对于`%`来计算位置能够提高运算效率，而只有当数组长度为2的幂次方时，`hash&(length-1)`才等价于`hash%length`

### 集合线程安全

- **线程安全**：`Vector`、`HashTable`、`Properties`
- **线程不安全**：`ArrayList`、`LinkedList`、`HashSet`、`TreeSet`、`HashMap`、`TreeMap`

#### 多线程场景下使用ArrayListd的结果和解决方法

两个线程同时对一个`ArrayList`进行`add()`操作，可能的**错误结果**

- **数组下标越界**

  - 线程首先要检查容量，必要时进行扩容
  - 每当在数组边界处，如果A线程和B线程同时进入并检查容量，也就是它们都执行完`ensureCapacityInternal()`方法，因为还有一个空间，所以不进行扩容
  - 此时如果A暂停下来，B成功自增。然后接着A从`elementData[size++] = e`开始执行，由于A之前已经检查过没有扩容，而B成功自增使得现在没有空余空间了，此时A就会发生数组下标越界问题

- **只改变了一次**

  - `size++`是`size = size + 1`，这一行代码包括三个步骤

    - 先读取`size`，然后将`size`加1，最后将这个新值写回到`size`
  - 此时如果A线程和B线程同时读取到`size`的值10，B先自增成功`size`的值变成11，然后A读到的`size`值也是10，所以自增后写入`size`被更新成11
  - 也就是说两次自增，实际上`size`只增大了1，因此最后的`size`会小于实际应该更新的值

**解决方法**

- **最常用的方法**：通过`Collections`的`synchronizedList()`方法将`ArrayList`转换成线程安全的容器后再使用
- 使用线程安全的`CopyOnWriteArrayList`代替线程不安全的`ArrayList`
- 为`list.add()`方法加锁



#### HashMap多线程操作导致死循环问题

多线程操作下进行`put`操作会导致`HashMap`死循环

- 因为`HashMap`的扩容`resize()`方法是由**新建一个数组，然后复制原数据到新的数组中**，而数组节点可能拉了一条链表，所以还需要**复制链表**，**而多线程操作有可能导致环形链表**

**问题**

两个线程同时进行扩容操作

- 当前`HashMap`的大小为2（临界值为1），**散列地址值分别为0和1**，在散列地址0处有元素A和B，
- 这时候要添加C，C经过hash运算得到散列地址为1，这时候由于超过了临界值，空间不够，此时线程1需要调用`resize()`方法进行扩容
- 此时线程2也进入，也

### Iterator有什么特点

- `iterator`对象称为**迭代器**，主要用于遍历`Collection`集合中的元素

  - **GOF**给**迭代器模式**的定义为：**提供一种方法访问一个容器(container)对象中各个元素，而又不需暴露该对象的内部细节**
  - 即迭代器模式就是为容器而生
- **`iterator`必须依附于一个集合类对象而存在，`iterator`本身不具有装载数据对象的功能**
- `iterator`遍历集合元素的过程中**不允许线程对集合元素进行修改**，否则会抛出`ConcurrentModificationEception`异常
- `iterator`遍历集合元素的过程中可以通过**迭代器对象的`remove()`方法来移除集合中的元素**，删除的是上一次`next()`方法返回的对象
- 集合对象每次调用`iterator()`方法都得到**一个全新的迭代器对象**，**默认游标都在集合的第一个元素之前**，调用`next()`方法会先移动游标，再返回元素

## 多线程

### 线程创建

1. 继承`Thread`类
2. 实现`Runnable`接口
3. 实现`Callable`接口
3. 由线程池创建并管理

> 重写`run()`方法：**线程体**
>
> `Thread`类实现了`Runnable`接口

**比较**

推荐使用`Runnable`接口

- **避免单继承局限性**
- **方便同一个对象被多个线程共享使用**
  - 适合多个相同线程来处理同一份资源

### 线程启动

通过`start()`方法启动线程

- **Java的线程是不允许启动两次的**，一个线程对象只能调用一次`start()`方法启动
  - 重复调用抛出异常（运行时异常）
- 直接调用`run()`无法开启一个新线程
  - `run()`方法**只是一个类中的普通方法**，直接执行和普通的方法没区别
- `start()`方法首先做了创建线程等一系列工作，然后调用`run()`方法
  - **即`start()`方法是在一个新的线程上面去调用`run()`方法**，`run()`方法则是在调用`run()`方法的当前的线程当中执行

#### 静态代理

**StaticProxy**

`new Thread(Runnable).start();`

- **真实对象和代理对象都要实现同一个接口**
- **代理对象要代理真实对象**

**优点**

- **真实对象专注于自己的工作**
- 代理对象可以做真实对象做不了的工作

```java
package com.ink.Thread;

public class RunnableTest implements Runnable{
    @Override
    public void run() {
        for (int i = 0; i < 20; i++) {
            System.out.println("子线程执行" + i);
        }
    }

    public static void main(String[] args) {
        RunnableTest runnableTest = new RunnableTest();
        new Thread(runnableTest).start();
    }
}
```

### 线程终止

- `run()`方法完成后线程终止
  - 有时`run()`方法是永远不会结束的，比如在服务端程序中**使用线程进行监听客户端请求**
- 使用`stop()`方法强行终止线程
  - **不推荐使用**，因为stop和suspend、resume一样，可能发生不可预料的结果，不知道资源是否释放
- 使用`interrupt()`方法中断线程

### 线程状态

**生命周期状态**

1. 创建（`NEW`）
   1. 当一个`Thread`类或其子类的对象被**声明并创建**时，新生的线程对象处于创建状态
   1. 还没有开始执行，即还没有调用`start()`方法
2. 就绪（`RUNNABLE`）
   1. 处于创建状态的线程被`start()`后将进入线程队列**等待CPU时间片**
   2. 此时它已具备了运行的条件，只是没分配到CPU资源
3. 运行（`RUNNING`）
   1. 当就绪的线程被调度并获得CPU资源时就进入运行状态
   2. `run()`方法定义了**线程的操作和功能**
4. 阻塞（`BLOCKED`）
   1. 在某种特殊情况下，被人为挂起或执行输入输出操作时，**让出CPU**并临时中止自己的执行，进入阻塞状态
   1. 在执行过程中遇到`synchronized`同步块就会进入`BLOCKED`阻塞状态，直到获取到请求的锁
5. 等待（`WAITING`/`TIMED_WATING`）
   1. 表示等待，前者是无时间限制的等待，后者是有时限的等待
   2. 等待可以是执行`wait()`方法后等待`notify()`方法将其唤醒，也可以是通过`join()`方法等待的线程等待目标线程的执行结束

6. 死亡（`DEAD`）
   1. 线程完成了它的全部工作或线程被提前强制性地中止或出现异常导致结束
   2. **结束后的线程不能再次启动**

### 线程通信

- `wait()`
  - **调用方法的必要条件**：当前线程必须具有对该对象的**锁**
  - 在当前线程中调用，**让当前线程挂起并放弃CPU、同步资源并等待，让别的线程可访问并修改共享资源**
  - 调用`wait()`后，当前线程将**释放对象监的锁** ，然后进入等待
  - 当前线程**排队等候**其他线程调用`notify()`或`notifyAll()`方法唤醒，唤醒后**等待重新获得对象的锁后**后才能**从断点处**继续执行
- `notify()`
  - **调用方法的必要条件**：当前线程必须具有对该对象的**锁**
  - 唤醒正在排队等待同步资源的线程中**优先级最高者**
- `notifyAll()`
  - **调用方法的必要条件**：当前线程必须具有对该对象的**锁**
  - 唤醒正在排队等待资源的所有线程

#### wait()，notify()与sleep()的区别

- `sleep()`：（阻塞）使线程在指定的时间内进入**阻塞状态**，不能得到CPU时间，指定时间结束后线程重新进入可执行状态
- `yield()`：（就绪）使线程放弃CPU执行时间，但是**不使线程阻塞，线程从运行状态进入就绪状态**，随时可能再次获取CPU时间
- `wait()`：（阻塞）使线程进入**阻塞状态**，`wait()`在调用之前必须先获得对象的锁。

**相同**

- 都可以使线程堵塞
- 都可以响应中断

**区别**

- 为了**防止死锁和永久等待**，`wait()`，`notify()`和`notifyAll()`只能在**同步方法**或者**同步方法块**中使用，`sleep()`没有这个限制
  - 否则会抛出`IllegalMonitorStateException`异常
- `wait()`调用后会释放锁，**`sleep()`调用后不会释放锁**
- `sleep()`必须要指定时间参数，`wait()`可以指定时间参数
- `sleep()`定义在`Thread`类中，`wait()`定义在`Object`类中
  - 定义在`Object`类中是**因为Java中每个类都可以是一把锁**

#### 为什么wait()和notify()定义在Object类，sleep()定义在Thread类

`wait()`，`notify()`和`notifyAll()`被定义在`Object`类中的原因

- **Java提供的锁是对象级的而不是线程级的**，每个对象都有个一个锁
- 线程是可以获得这个对象的，因此如果线程需要等待某些锁，只要调用对象中的`wait()`方法就可以了
- `wait()`方法如果定义在`Thread`类中，那么**线程正在等待的是哪个锁就不明确了**
- 也就是说`wait()`，`notify()`和`notifyAll()`都是**锁级别的操作**，所以把它们定义在`Object`类中是因为**锁是属于对象的原因**
  - 任意对象都可以作为`synchronized`的同步锁， 因此这三个方法只能在`Object`类中声明
- `sleep()`的作用是让线程在预期的时间内执行，其他时候不要来占用CPU资源，可以理解为**`sleep()`是属于线程级别的**，是为了让线程在限定的时间后去执行，并且`sleep()`是不会去释放锁的

#### 被notify()唤醒的线程为什么不能立即得到执行

- 因为执行`notify()`的线程**不会立刻释放锁**，`wait()`的线程也**不能立刻获得锁**，只有等到执行`notify()`的线程退出同步块后**才释放锁**，此时其他处于`wait()`状态的线程才能获得该锁再执行

### 线程池

`ThreadPool`：**并发框架**，用来管理一组线程，管理线程的生命周期

- 让线程进入`while(true)`获取任务状态，通过**阻塞队列**来管理任务，**没有任务的时候线程处于阻塞阶段**

**优点**

1. **降低资源消耗**：通过重复利用已经创建的线程**降低线程创建的和销毁造成的消耗**
   1. 例如工作线程Woker会**无限循环**获取阻塞队列中的任务来执行
2. **提高响应速度**： 当任务到达时，任务可以**不需要等到线程创建就能立即执行**
3. **提高线程的可管理性**： 线程是稀缺资源，Java的线程池可以对线程资源进行**统一分配、调优和监控**

#### 线程是不是越多越好

- 不是，cpu切换线程需要切换上下文信息，这个过程也是需要消耗资源的，如果线程过多，cpu疲于切换线程，效率低下

#### Executor、ExecutorService、ThreadPoolExecutor、ForkJoinPool

- `Executor`是线程池的顶级父接口，定义了`execute`方法
-  `ExecutorService`继承`Executor`，完善了线程池的声明周期管理方法
-  `ThreadPoolExecutor`是**线程池的具体实现**，内部维护一个阻塞队列存储任务，实现了线程池的方法
-  `ForkJoinPool`是**线程池的具体实现**，拆分任务，并行执行

#### 线程池的工作流程

线程池在创建线程时会将线程封装成**工作线程**Woker，Woker在执行完任务后，不是立即销毁而是循环获取阻塞队列里的任务来执行

当一个新的任务到线程池时，线程池的处理流程如下

1. 线程池判断**核心线程池（`corePoolSize`）里的线程是否都在执行任务**， 如果不是，**创建一个新的工作线程来执行任务**，如果核心线程池里的线程都在执行任务，则不会创建新的线程，而是进入下个流程
   1. **即使有空闲的基本线程能执行该任务，也会创建新的线程**
   2. 如果调用了线程池的`prestartAllCoreThreads()`方法，**线程池会提前创建并启动所有基本线程**
2. 线程池判断**阻塞队列是否已满**，如果阻塞队列没有满，则将新提交的任务存储在阻塞队列中，如果阻塞队列已满，则进入下个流程
3. 线程池判断**线程池（`maximumPoolSize`）里的线程是否都处于工作状态**，如果不是，**创建一个新的工作线程来执行任务**，否则交给**饱和策略**来处理这个任务

> 当任务提交到线程池时，具体的处理流程是由`ThreadPoolExecutor`类的`execute()`方法去完成的

## 面向切面编程

AOP：Aspect oriented programming

- AOP 是 OOP（面向对象编程）的一种延续，OOP编程思想可以解决大部分的代码重复问题，但还是有一些重复代码问题解决不了，这部分重复的代码，一般统称为**横切逻辑代码**
  - 在多个纵向（顺序）流程中出现的相同子流程代码，称之为横切逻辑代码


横切逻辑代码存在问题

- 代码重复问题
- **横切逻辑代码和业务代码混杂在一起**，代码臃肿，不变维护

AOP提出**横向抽取机制**，将横切逻辑代码和业务逻辑代码分离，在根本上解耦合，避免横切逻辑代码重复

### SpringAOP

可以在方法调用的前后（不管是正常结束或是抛出异常）加入一些别的代码

- 这些代码不会污染业务逻辑，只需要定义一些规则，SpringAOP会通过**动态代理的方式自动在方法执行的前后调用这些新代码**

## MVC架构模式

> **架构模式**是一个通用的、可重用的解决方案，用于在给定上下文中的软件体系结构中经常出现的问题
>
> 架构模式与软件设计模式类似，但具有更广泛的范围

**模型-视图-控制器模式（Model-View-Controller）**，也称为MVC模式

- 用一种将**业务逻辑**、**数据**、**界面显示**分离的方法组织代码
- 传统的输入、处理和输出功能在一个逻辑的结构中，MVC则把软件系统分为三个基本部分
  - **模型**（Model）：负责**处理业务逻辑（包括数据交互）**
  - **视图**（View）：将**信息显示给用户**（可以定义多个视图）
  - **控制器**（Controller）：应用程序中**处理用户交互的部分**
    - 负责从视图读取请求和数据，处理后转发到对应的模型，最后将模型返回的结果返回给视图（对客户端做出响应）
    - 每个视图都有一个相关的控制器组件

MVC最重要的就是将**视图和模型数据分离**：**使用不同的视图对相同的数据进行展示**，分离可视和不可视的组件，能够对模型进行独立测试，因为分离了可视组件减少了外部依赖利于测试（数据库也是一种外部组件）

**优点**

- 耦合性低
- 重用性高
- 生命周期成本低
- 部署快
- 可维护性高
- 有利软件工程化管理

## 反射

### 反射是什么

- **允许任意一个类在运行时获取自身的类信息，并且可以操作这个类的方法和属性**，这种动态获取类信息和动态调用对象方法的功能称为Java的反射机制

**反射的核心**

- **JVM在运行时才动态加载类或调用方法/访问属性**
- 它不需要事先（写代码时或编译时）知道运行对象是谁，如`Class.ForName()`根本就没有指定某个特定的类，完全由传入的**类全限定名**决定
- 通过`new`的方式是知道运行时对象是哪个类的，反射避免了将程序写死

**反射的优点**

- 反射可以降低程序耦合性，提高程序的灵活性

> `new`是造成紧耦合的一大原因

### 反射什么时候使用

- **加载数据库驱动**
- Spring的IOC容器，根据XML配置文件中的类全限定名动态加载类
- 工厂方法模式

#### 给定一个Person对象，如何将该对象变成JSON表示

> 本质是考察Java反射

- 因为要实现一个通用的程序，可能根本不知道该类有哪些字段，所以不能通过`get()`和`set()`等方法来获取键值
- 使用反射的`getDeclaredFields()`可以获得其声明的字段，如果字段是`private`的，需要调用该字段的`f.setAccessible(true)`才能读取和修改该字段
- 得到map后再转化为json

### 反射有什么问题

**性能问题**

- 使用反射基本上是一种**解释操作**，用于字段和方法接入时要**远慢于**直接代码，因此反射机制主要应用在对灵活性和扩展性要求很高的系统框架上，普通程序不建议使用
- 反射包括了一些**动态类型**，所以JVM无法对这些代码进行优化，因此反射操作的效率要比那些非反射操作低得多，应该避免在经常被执行的代码或对性能要求很高的程序中使用反射

**内部暴露**

- **反射允许代码执行一些在正常情况下不被允许的操作**，比如**访问私有的属性和方法**，所以使用反射可能会导致意料之外的副作用
  - 代码有功能上的错误，降低可移植性
- 反射代码破坏了抽象性，因此当平台发生改变的时候，代码的行为就有可能也变化

## Java并发

[Java并发编程.md](../Java/Java并发编程.md)

Java中的锁类型

- 自旋锁
- 偏向锁/轻量级锁/重量级锁
- 乐观锁/悲观锁
- 可重入锁
- 独享锁/共享锁
- 互斥锁/读写锁
- 分段锁
- 公平锁/非公平锁

### 自旋锁

`Spinlock`

> 自旋：持续观察一个变量直到它发生改变的过程

**自旋锁**：一个线程在获取锁的时候，如果锁已经被其它线程获取，那么**该线程将循环等待（不会被阻塞），然后不断的判断锁是否能够被成功获取**，直到获取到锁才会退出循环

自旋锁通过一个**忙标志**`flag`表示锁是否被占用

- 当`flag = 0`时表示锁空闲
- 当一个线程成功将`flag`从`0`变为`1`时，表示该线程获得锁
  - 线程在`while`循环中尝试通过TAS（Test And Set）等硬件**原子指令**获取锁

**优点**

- 不会使线程状态发生切换，这就避免了操作系统**重新调度**和**上下文切换**的开销
  - **操作系统内核经常使用自旋锁**
- 自旋锁的性能在**多处理器**的场景下性能要比单处理器更好（假设线程均匀分布在多个CPU上）
  - 因为如果当前线程持有锁并很快释放，那么其他线程很可能在自旋的时候就能直接获取到这个锁，这样不会浪费整个时钟周期
  

**缺点**

- 在单处理器的场景下，如果锁已经被另一个线程持有，那么当前线程**在尝试加锁时需要将整个时间片空转完**，除非发生上下文切换，否则它是不可能获取到锁的
- 自旋锁可能会导致**饥饿**

因此，自旋锁适用于线程**持有锁的时间很短**的场景，线程持有锁的时间越长，则持有锁的线程被OS调度程序中断的风险越大，其他线程空转浪费时间片的概率也越大

### CAS

CAS是乐观锁的一种实现（自旋锁或乐观锁的核心操作）

- **CAS操作是由硬件支持的，现在的处理器基本支持原子化的CAS指令**
  - 依赖于CPU的`cmpxchg`指令实现

> CAS也是无锁的一种实现

### 互斥锁

`Mutex`

- 互斥锁需要操作系统的帮助。当一个线程访问其他线程持有的锁时，会被 OS 调度为阻塞状态（休眠），直到锁被释放后，再唤醒一个休眠的线程
- 互斥锁的开销主要体现在线程的**重新调度**和**上下文切换**上，获取锁的开销是比较大的，因此适用于线程**持有锁时间比较长**的场景
- 如果线程持有锁的时间比较短，使用互斥锁会因为频繁的线程切换而导致效率变差，大部分时间都花在了用户态到内核态的切换（系统调用）、重新调度（移到阻塞队列）和上下文切换（线程切换）上了，还不如使用自旋锁的效率高

### 可重入锁

#### synchornized和Reentrantlock的区别

- **底层实现**
  - `synchronized`**是JVM层面的锁，是Java关键字**，通过`monitor`对象来完成
  - `ReentrantLock` 是从jdk1.5 `java.util.concurrent.locks.Lock`提供的**API层面的锁**

- **锁的对象**
  - `synchronzied`锁的是对象，**锁保存在对象头里面**，根据对象头数据来标识是否有线程获得锁（争抢锁）
  - `ReentrantLock`**锁的是线程**，根据进入的线程和`state`标识锁的获得（争抢）

- **手动释放**
  - `synchronized` 不需要用户去手动释放锁，代码执行完后系统会自动让线程释放对锁的占用
  - `ReentrantLock`需要用户去手动释放锁，如果没有手动释放锁，**就可能导致死锁现象**
  - 一般通过`lock()`和`unlock()`方法来完成，**使用释放更加灵活**

- **中断**：
  - `synchronized`**是不可中断类型的锁**，除非加锁的代码中出现异常或正常执行完成
  -  `ReentrantLock`**可以响应中断**，通过`trylock(long timeout,TimeUnit unit)`设置超时方法或者使用`lockInterruptibly()`方法进行中断

- **公平锁**
  - `synchronized`是**非公平锁**
  - `ReentrantLock`**可以选公平锁也可以选非公平锁**，默认`false`非公平锁

- **锁是否可绑定条件（Condition）**
  - `synchronized`不能绑定，通过`Object`类的`wait()/notify()/notifyAll()`方法**要么随机唤醒一个线程要么唤醒全部线程**
  - `ReentrantLock`通过绑定Condition结合`await()/singal()`方法实现线程的**精确唤醒**

#### 保证线程安全的方式

根据深入理解java虚拟机，主要分为三部分

- 互斥同步
- 非阻塞同步
- 无同步方案

### 什么是指令重排序

在实际运行时，代码指令可能并不是严格按照代码语句顺序执行的

- 大多数现代微处理器都会采用**将指令乱序执行**（`out-of-order execution`，简称OoOE或OOE）的方法，在条件允许的情况下，**直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待**
- 通过乱序执行的技术，处理器可以大大提高执行效率，这就是指令重排

### 什么是内存屏障

内存屏障，也叫**内存栅栏**，是**一种CPU指令**，用于**控制特定条件下的重排序和内存可见性问题**

- **LoadLoad屏障**：对于`Load1; LoadLoad; Load2`这样的语句，在`Load2`及后续读取操作要读取的数据被访问前，**保证`Load1`要读取的数据被读取完毕**
- **StoreStore屏障**：对于`Store1; StoreStore; Store2`这样的语句，在`Store2`及后续写入操作执行前，**保证Store1的写入操作对其它处理器可见**
- **LoadStore屏障**：对于`Load1; LoadStore; Store2`这样的语句，在`Store2`及后续写入操作执行前，**保证`Load1`要读取的数据被读取完毕**
- **StoreLoad屏障**：对于`Store1; StoreLoad; Load2`这样的语句，在`Load2`及后续所有读取操作执行前，**保证`Store1`的写入对所有处理器可见**
  - 四种屏障中开销最大
  - 在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能

## Java虚拟机

[JVM.md](../Java/JVM.md)

### 组成结构

#### 堆和栈的区别

**物理地址**

- **堆的物理地址分配是不连续的**，因此性能慢些
- 在GC的时候也要考虑到不连续的分配，所以有各种算法，比如标记-消除，标记-复制，标记-整理，分代（新生代使用复制算法，老年代使用整理）

- **栈的物理地址分配是连续的**，所以性能快

**内存**

- **堆是不连续的**，所以**分配的内存是在运行期确认的，大小不固定**，一般堆大小远远大于栈
- **栈是连续的**，所以**分配的内存大小要在编译期就确认，大小是固定的**

**存放的内容**

- 堆存放的是**对象的实例**和**数组**，更关注的是数据的存储
- 栈存放**局部变量**，**操作数栈**，**返回结果**，更关注的是程序方法的执行

**程序的可见度**

- 堆对于整个应用程序都是共享、可见的
- **栈只对于线程是可见的**，是线程私有，生命周期和线程相同

### 类加载机制

1. 简单说说类加载过程，里面执行了哪些操作？
2. 对类加载器有了解吗？

#### 双亲委派机制

- 一个类加载器收到类加载请求之后，**首先判断当前类是否被加载过**，已经被加载的类会直接返回
- 如果没有被加载，除了顶层的**启动类加载器**以外，其余的类加载器在加载之前，都会**委派给它的父加载器进行加载**，一层层向上传递，只有当父类加载器无法完成时才尝试自己加载

##### 双亲委派机制的优点

- 避免类的重复加载，**相同的类被不同的类加载器加载会产生不同的类**，双亲委派保证了Java程序的稳定运行
- 保证核心API不被修改

##### 为什么需要双亲委派模式

- 如果没有双亲委派，用户就可以自己定义一个`java.lang.Object`的同名类，`java.lang.String`的同名类，并把它放到`ClassPath`中，**那么类之间的比较结果及类的唯一性将无法保证**

- **所以需要双亲委派模型防止内存中出现多份同样的字节码**

##### 怎么打破双亲委派模型

- 继承`ClassLoader`类
- 重写`loadClass`和`findClass`方法

> Tomcat就打破了双亲委派

### 类文件结构

- 介绍一下Class类文件结构
- 常量池主要存放的是那两大常量？
- Class文件的继承关系是如何确定的？
- 字段表、方法表、属性表主要包含那些信息？

### 垃圾收集

#### 哪些可以作为GC Roots

**GC Roots是一组必须活跃的引用**，即程序接下来通过**直接引用或者间接引用**能够访问到的潜在被使用的对象

GC Roots包括

- Java线程中当前所有正在被调用的方法的**引用类型参数**、**局部变量**、**临时值等**，即**栈帧相关的各种引用**
- 所有当前被加载的Java类
- Java类的**引用类型静态变量**
- 运行时常量池里的**引用类型常量**（`String`或`Class`类型）
- **JVM内部数据结构的一些引用**，比如`sun.jvm.hotspot.memory.Universe`类
- **用于同步的监控对象**，比如调用了对象的`wait()`方法
- JNI handles，包括global handles和local handles

这些GC Roots大体可以分为三大类

- 活动线程相关的各种引用
- 类的静态变量的引用
- JNI引用

**注意**

- **是引用而不是对象，对象是不能作为GC Roots的**
- **GC过程是找出所有活对象，并把其余空间认定为无用，而不是找出所有死掉的对象，并回收它们占用的空间**

#### 对象在什么时候可以被回收，调用finalize方法后一定会被回收吗？

在经过可达性分析后，**到GC Roots不可达的对象可以被回收（但并不是一定会被回收，至少要经过两次标记）**，此时对象被第一次标记，并进行一次判断：

- 如果该对象没有调用过或者没有重写`finalize()`方法，那么**在第二次标记后就可以被回收了**
- 否则该对象会进入一个FQueue中，**稍后由JVM建立的一个Finalizer线程中去执行回收**
  - 此时若对象在`finalize(`)中自救，即和引用链上的任意一个对象建立引用关系，到GC Roots又可达了，**在第二次标记时它会被移除出即将回收的集合**
  - 如果在finalize中没有逃脱，那要被回收，因此finalize方法被调用后，对象不一定会被回收

#### 对象都是优先分配在新生代上的吗

**不是**

- 当新生代内存不够时，**老年代分配担保**
- **大对象**直接在老年代分配

#### 为什么不在新生代使用标记整理算法？或者在老年代使用复制算法？

#### JVM新生代中为什么要分为Eden和Survivor

如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代，老年代很快会被填满，触发Major GC，而**老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多**，所以需要分为Eden和Survivor

**Survivor存在的意义就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象才会被送到老年代**

设置两个Survivor区最大的好处就是**解决了碎片化**

- 刚刚新建的对象在Eden中，经历一次Minor GC，Eden中的存活对象就会被移动到第一块survivor space S0，Eden被清空
- 等Eden区再满了，就再触发一次Minor GC，Eden和S0中的存活对象又会被复制送入第二块survivor space S1
  - 这个过程非常重要，因为复制算法**保证了S1中来自S0和Eden两部分的存活对象占用连续的内存空间**，避免了碎片化的发生

> 所以新生代可用空间其实只有其容量的90%

#### JVM中一次完整的GC流程，对象如何晋升到老年代

当Eden区的空间满了，JVM就会触发一次Minor GC，收集新生代的垃圾，存活下来的对象会转移到Survivor区

大对象（**需要大量连续内存空间的Java对象**，如很长的字符串）**直接进入老年代**

- 如果对象在Eden出生并且经过第一次Minor GC后仍然存活被Survivor容纳的话，年龄设为1，每熬过一次Minor GC，年龄+1，若年龄超过一定限制（默认15），就会晋升到老年代，即**长期存活的对象进入老年代**
- 如果Survivor不能容纳存活的对象，则会通过**分配担保机制**转移到老年代

**老年代满了后Minor GC之后通常就会进行Full GC**，清理整个内存堆

- 通过担保机制进入老年代的对象如果比老年代的内存空间还大，也会发生Full GC
- Major GC发生在老年代，经常会伴随至少一次Minor GC，比Minor GC慢 10倍以上

#### Java会存在内存泄漏吗

内存泄漏是指**不再被使用的对象或者变量一直被占据在内存中**

> 理论上来说Java是有垃圾回收机制的，不再被使用的对象会被GC自动回收掉，自动从内存中清除

但是即使这样，Java也还是存在着内存泄漏的情况

- **长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露**，尽管短生命周期对象已经不再需要，但是**因为长生命周期对象持有它的引用而导致不能被回收**，就会导致内存泄漏

# 计算机网络

## 网络结构

### OSI 7层模型

- 应用层：**针对特定应用**的协议，为应用程序提供服务。如电子邮件、远程登录、文件传输等协议
- 表示层：主要负责**数据格式的转换**，把不同表现形式的信息转换成适合网络传输的格式
- 会话层：通信管理，负责建立和断开**通信连接**，即何时建立连接、何时断开连接以及保持多久的连接
- 传输层：在两个**通信结点**（端到端）之间负责数据的传输，起着可靠传输的作用
- 网络层：**路由选择**，在多个网络之间转发数据包，负责将数据包传送到目标地址
- 数据链路层：负责物理层面上互联设备之间的通信传输（例如一个以太网相连的两个节点之间的通信），是数据帧与比特流之间的转换
- 物理层：主要是0，1比特流与电子信号的高低电平之间的转换

> 网络层是针对主机与主机之间的通信，而传输层针对的是不同主机进程之间的通信
>
> 网络层负责将数据包从源IP地址转发到目标IP地址，而传输层负责将数据包再递交给主机中对应端口的进程

## TCP

基于TCP的协议：HTTP、HTTPS、Telnet、FTP、SMTP

### TCP头部

标志位：URG、ACK、PSH、RST、SYN、FIN

- SYN：**发起一个新连接**
- ACK：**确认序号**ack有效
  - 建立连接后所有的报文段ACK=1
- FIN：**释放一个连接**
- PSH：接收方应该尽快将这个报文交给应用层
  - 不用等待缓存满
- RST：重置连接
- URG：紧急指针（urgent pointer）有效
  - 紧急数据，尽快传送

### 三次握手建立连接

- 第一次握手：客户端随机产生一个自己的初始序列号seq，令自己的SYN=1，发送给服务器，进入`SYN_SENT`状态
  - **SYN=1，seq=x**
- 第二次握手：服务器收到客户端的SYN=1之后，知道是客户端请求建立连接，令自己的SYN=1，ACK=1，产生一个ack=seq+1表示确认，再随机产生一个自己的初始序列号seq，发送给客户端，进入`SYN_RCVD`状态
  - **SYN=1，ACK=1，seq=y，ack=x+1**
- 第三次握手：客户端检查ack是否等于seq+1，ACK是否等于1，检查正确之后令自己的ACK=1，产生一个ack=seq+1，发送给服务器，进入`ESTABLISHED`状态
  - **无SYN，ACK=1，seq=x+1，ack=y+1**

服务器检查ACK是否等于1和ack是否等于seq+1后，也进入`ESTABLISHED`状态，代表三次握手完成，连接建立

> 当一个连接被建立或被终止时，交换的报文段只包含TCP头部，而没有数据

### 第三次握手中如果客户端的ACK未送达服务器会怎么样

由于服务器没有收到客户端的ACK确认，会重发之前的SYN+ACK

- 默认重发五次，之后自动关闭连接进入`CLOSED`状态
- 客户端收到后会重新传ACK给服务器

### 为什么TCP建立连接不能是两次握手

> 等价问题：三次的目的是什么？能否通过两次达到同样的目的
>

**不采用三次握手，那么只要服务器发出确认，连接就建立了**

- **两次握手服务器无法确认客户端是否正确接收第二次握手的报文**，也无法保证服务器和客户端之间成功互换初始序列号

- 可能会出现**已失效的客户端连接请求报文段又传到了服务器端**
   - 客户端发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致**延误到连接释放以后的某个时间才到达服务器**
   - 服务器收到失效的连接请求报文段后，**会误认为是客户端再次发出的一个新的连接请求**，于是就向客户端发出确认报文段，同意建立连接
   - 而客户端并没有发出建立连接的请求，因此不会理睬服务器的确认，也不会向服务器发送数据。**但服务器却以为新的连接已经建立**，并一直等待客户端发来数据

三次握手问题的本质是**信道不可靠，但是通信双发需要就某个问题达成一致**

- 要解决这个问题，无论在消息中包含什么信息，**三次通信是理论上的最小值**
- 所以三次握手不是TCP本身的要求，而是为了满足"**在不可靠信道上可靠地传输信息**"这一需求所导致的

### TCP建立连接能不能是四次握手

可以，但是会降低传输的效率

- 第二次握手时服务器只发送ACK和ack
- **服务器的SYN和seq在第三次握手时发送**
- 原来协议中的第三次握手变为第四次握手

> 即四次握手中的二，三可以合并成为三次握手

### 四次挥手释放连接

- 第一次挥手：客户端将FIN置为1，发送一个序列号seq给服务器，进入`FIN_WAIT_1`状态
  - FIN=1表示客户端已经没有要发送的数据，主动请求释放连接
- 第二次挥手：服务器收到FIN之后，令自己的ACK=1，产生一个ack=seq+1表示确认，进入`CLOSE_WAIT`状态
  - 客户端已经不发送的数据了，但仍可以接受服务器发来的数据
  - 即客户端向服务器的单向连接被释放
- 第三次挥手：服务器将FIN置1，发送一个序列号seq给客户端，进入`LAST_ACK`状态
  - FIN=1表示接服务器已经把数据发送完了，请求释放连接
- 第四次挥手：客户端收到服务器的FIN后，进入`TIME_WAIT`状态，令自己的ACK=1，产生一个ack=seq+1表示确认。服务器收到ACK后，确认ack后变为`CLOSED`状态，不再向客户端发送数据。
  - 客户端**等待2*MSL**（报文段最长寿命）时间后，也进入`CLOSED`状态，完成四次挥手

> 2，3次分开挥手，先发送ACK，再发送FIN，是因为服务器可能还没有发送完数据，不能一次性将确认ACK报文和FIN报文发给客户端，所以这里多出来了一次
>
> 如果客户端没有收到第二次挥手的ACK确认，会重新发送释放连接请求

### 第四次挥手的`TIME_WAIT`有什么用

- 第四次挥手时，**客户端发送给服务器的ACK有可能丢失，`TIME_WAIT`状态就是用来重发可能丢失的ACK报文**

- 如果服务器没有收到ACK，就会重发FIN，**如果客户端在2MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL**，防止服务器没有收到ACK而不断重发FIN

- 如果直到2MSL客户端都没有再次收到FIN，那么客户端推断ACK已经被成功接收，则结束TCP连接


> MSL（Maximum Segment Lifetime），指一个片段在网络中最大的存活时间，2MSL就是**一个发送和一个回复所需的最大时间**

### TCP的流量控制

控制发送方的发送速度，避免接**收方处理不过来**产生网络拥塞或丢包

> 滑动窗口（Sliding Window）实现

通信过程中，接收方根据自己接收缓存的大小，通过**设置确认报文段中的TCP首部字段中的窗口字段**动态调整发送方发送窗口的大小

- **发送窗口 = min(接收窗口，拥塞窗口)**
- 发送窗口的大小指的是**无需等待确认应答而可以继续发送数据的最大值**，即不需要接收端的应答可以一次连续的发送数据

**为什么使用滑动窗口**

- TCP采用**确认应答**策略
- 对每一个发送的数据段都会给一个ACK确认，收到ACK后再发送下一个数据段，这样做性能比较差，尤其是往返时间长的时候

使用滑动窗口可以一次发送多条数据，从而就提高了性能

**滑动窗口中的数据分为两种**

- 已经发送，但还没有收到确认的
- 可以发送，但还没有发送的



### TCP的拥塞控制

控制发送方的发送速度，避免**网络来不及处理**从而导致网络拥塞

- 对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏，会造成一部分网络资源丢失掉

- 网络资源：链路容量（带宽）、交换结点中的缓存和处理机等

**前提**：接收窗口足够大，**发送窗口取决于网络的拥塞程度，即拥塞窗口**（cwnd）

拥塞控制主要由四个算法组成

- **慢启动（Slow Start）**
- **拥塞避免（Congestion voidance）**
- **快重传 （Fast Retransmit）**
- **快恢复（Fast Recovery）**

#### 慢启动和拥塞避免

**慢启动**：指数增长

- 开始发送时，将**拥塞窗口大小设为1MSS**（最大报文段），每收到一个新的**确认报文段**，窗口大小+1
- 即**每经过一个轮次，窗口大小翻倍**，指数增大（1-2-4-8...）
  - 轮次时间RTT也变大

> 慢启动是指一开始像网络注入的报文段少，而不是指拥塞窗口增长慢

**拥塞避免**：线性增长

- **每经过一个轮次，窗口大小+1**
  - 轮次时间不变

建立连接后还会**给拥塞窗口设置一个慢启动的门限值**ssthresh，为了避免拥塞窗口过大（指数增长太快）

- cwnd < ssthresh：使用慢启动
- cwnd = ssthresh：慢启动，拥塞避免均可
- cwnd > ssthresh：使用拥塞避免
  - 如果一开始拥塞窗口就大于门限值，则直接使用拥塞避免算法


> 拥塞避免不是指完全避免拥塞，而是将拥塞窗口换成线性增加，使得网络比较不容易出现拥塞

无论是慢启动还是拥塞避免，当**达到网络拥塞值时**（发现丢包判断拥塞）

- **将门限值ssthresh降低为此时发送窗口大小的一半**，但不能小于2
- 将拥塞窗口cwnd设为1，开始慢启动过程

#### 快重传和快恢复

用于**改进TCP的性能**，新增的两个拥塞控制算法

- **有时候个别报文段会在网络中丢失，但实际上网络并没有发生拥塞**
- 报文段丢失会导致发送方触发超时重传，并且认为网络拥塞了，这时发送方会降低门限值，启动慢启动算法，将拥塞窗口设为1，**降低了传输效率**

**快重传**

使用冗余ACK来判定丢包，快速重传，避免触发超时计时器，这样就不会认为网络拥塞从而降低了拥塞窗口，提高了网络吞吐量

- 要求接收方在收到一个**失序的报文段**后就立刻发出**冗余ACK**而不要等到自己发送数据时**捎带确认**
  - **冗余ACK**就是再发一次之前收到的报文段的确认，即收到的有序报文段的最后一个的确认
- 规定发送方**只要收到三个冗余ACK就立即重传**对方尚未收到的报文段
  - 不必继续等待设置的**重传计时器**时间到期

**快恢复**

当发送方收到三个冗余ACK时，知道只是丢失了个别报文段而不是网络拥塞，所以不启动慢启动算法，而是执行拥塞避免算法

- 将门限值**ssthresh降低为此时拥塞窗口cwnd大小的一半**
- 将拥塞窗口cwnd设置为此时的ssthresh
- **执行拥塞避免算法**

> 还有一个就是因为如果网络出现拥塞的话就不会收到三个冗余ACK，所以发送方认为现在网络没有出现拥塞

### TCP拥塞控制和流量控制的区别

**拥塞控制通常表示的是一个全局性的过程**，它会涉及到网络中所有的主机、路由器和降低网络传输性能的所有因素

**流量控制发生在发送端和接收端之间，只是点到点之间的控制**

**相同点**

- **现象都是丢包**
- 实现机制都是让发送方发的慢一点，发的少一点

**不同点**

- **丢包位置不同**

  - 流量控制丢包位置是在**接收端**上

  - 拥塞控制丢包位置是在**路由器**上

- **作用的对象不同**
  - 流量控制的对象是**接收方**，怕发送方发的太快，使得接收方来不及处理
  - 拥塞控制的对象是**网络**，怕发送方发的太快，造成网络拥塞，使得网络来不及处理

### TCP粘包

**TCP是面向连接的、可靠的流式传输协议**

- **流式传输**是指数据的传输方式是**字节流**式的，**流是没有边界的**，所以**TCP根本不存在所谓粘包一说**

- 应用程序首先要将自己的数据**通过套接字发送**，应用层交付给TCP的是**结构化的数据**（表示层）
- TCP把应用程序交付下来的数据仅仅看成是一连串的**无结构**的**字节流**，并不知道所传送的字节流的含义

TCP粘包是指

- 发送方发送的**若干包数据到达接收方时粘成了一包**
- 从接收缓冲区来看，**后一包数据的头紧接着前一包数据的尾**

> **应用层协议在设计的时候，是需要充分考虑到数据解析和还原的问题，如果设计不好，导致数据无法还原，那是应用层协议设计不佳**，并不是说TCP天然有粘包问题

出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方

1. 由**TCP连接复用**造成的粘包问题
   1. 如果没有复用，一个连接只提供给端到端的两个进程使用，这是数据的传输方和发送方都是**约定好了数据格式的**，但是连接复用则是**多个进程**使用一个TCP连接，此时**多种不同结构**的数据通过TCP流式传输，边界分割就可能出现粘包问题
2. TCP默认使用的**Nagle算法**造成的粘包问题
   1. Nagle算法是指，只有上一个分组得到确认，才会发送下一个分组，收集多个小分组，在一个确认到来时一起发送
   2. 所以将**多个分组拼成一个数据段发送出去**时如果没有处理好边界，在解包的时候会发生粘包问题
3. 接收方**不及时接收缓冲区的包**造成的粘包问题
   1. TCP接收到数据包时并不会马上交到应用层进行处理，或者说应用层并不会立即处理
   2. TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组
   3. 如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包
4. **数据包过大**造成的粘包问题
5. 流量控制和拥塞控制造成的粘包问题

> Nagle算法
>
> - 在socket网络编程中，都是端到端通信，由`<cport,sport,cip,sip,协议>`这个五元组标识一条TCP连接，发送端和接收端都有成对的socket
> - 发送端为了将多个包更加高效的的发给接收端，于是采用了Nagle算法，将多次间隔较小、数据量较小的数据合并成一个数据量大的数据块，然后进行封包
> - 所以接收端就必须使用高效科学的拆包机制来分辨这些数据

**处理粘包问题**

当发送方发送的多组数据毫不相干，或者是并列关系，就要处理粘包

> 同一块数据的不同部分就不需要处理粘包

1. 发送方造成的粘包问题，可以关闭Nagle算法
2. **接收方没有办法来处理粘包现象**，只能将问题交给应用层来处理
3. 应用层从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成
   1. **格式化数据**：每条数据有固定的格式（开始符，结束符）
      1. 选择开始符和结束符时要确保数据的内部不包含开始和结束符
   2. **发送长度**：发送数据时，将数据的长度一并发送

**UDP为什么不会产生粘包问题**

- **UDP是面向报文段的**，不是流式的

### TCP可靠传输

可靠传输是指

- 传输的**信道不产生差错**
- 保证传输数据的**正确性，无差错，不丢失，不重复且按顺序到达**

TCP实现可靠传输

- 应用数据被分割成TCP认为最适合发送的**块**进行传输
- **超时重传**，TCP发出一个分组后，它启动一个定时器，等接收方确认收到这个分组
  - 如果发送方不能及时收到一个确认，将重传给接收方
- **序号**，用于检测丢失的分组和冗余的分组
- **确认**，告知对方已经正确收到的分组以及期望的下一个分组
- **校验和**，校验数据在传输过程中是否发生改变，如校验有错则丢弃分组；
- **流量控制**，使用滑动窗口，发送窗口的大小由接收窗口和拥塞窗口的的大小决定
  - 当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失
- **拥塞控制**：当网络拥塞时，减少数据的发送

### TCP与UDP的区别

- TCP是面向连接的，UDP是无连接的
- TCP是可靠的，UDP不可靠
  - 指UDP接收方收到报文后，**不需要给出任何确认**
- **TCP只支持点对点通信**，UDP支持一对一、一对多、多对一、多对多
- **TCP是面向字节流的，UDP是面向报文的**
  - 发送数据时以字节为单位，一个数据包可以拆分成若干组进行发送
  - **UDP一个报文只能一次发完**
  - 所以**TCP无界，UDP有界**
- **TCP有拥塞控制机制，UDP没有**
- TCP首部开销（20字节）比UDP首部开销（8字节）要大
- **使用UDP的主机不需要维持复杂的连接状态表**

## UDP

基于UDP的协议：DHCP、DNS、SNMP、TFTP、BOOTP

## DNS

Domain Name System：DNS，域名系统

- 应用层协议
- 是一种组织成**域层次结构**的计算机和网络服务命名系统
  - 域名的层级关系类似一个**树状结构**
- DNS中的域名用**句点**分隔，代表了不同层次之间的**界限**
  - 在域名中，**越靠右**的位置表示其层级**越高**

> 用户主机上运行着DNS客户端

**根DNS服务器**

- **顶级DNS服务器**（com，cn，org）
  - **权威DNS服务器**（google.cn，baidu.com）

其中**根DNS服务器信息保存在所有的DNS服务器中**，任何DNS服务器都可以找到并访问根DNS服务器

DNS 查询共有两类

- 递归查询
- 迭代查询

**递归查询**是指当A向B查询某个域名的IP地址时，如果B不知道被查询的域名的IP地址，那么B会替A向更上层的服务器发起查询，将查询结果返回 A

**迭代查询**是指当A向B查询某个域名的IP地址时，如果B不知道被查询的域名的IP地址，B会告诉A下一步应该向哪个服务器查询，由A自己去查

> 一般来说，主机向本地域名服务器的查询是递归查询，而本地域名服务器向根域名服务器的查询是迭代查询

### 为什么DNS使用UDP

**DNS主要基于运输层的UDP协议**

User Datagram Protocol：无连接的，尽最大能力交付的不可靠数据连接

- 一次UDP的信息交换可以短到只包含两个包：一个查询包和一个响应包。一次TCP的信息交换则至少包含9个包：三次握手、一个查询包、一个响应包和四次挥手


- 考虑到效率原因，TCP连接的开销大，所以采用UDP作为DNS的运输层协议

### 浏览器提示找不到IP地址时如何解决



### 在浏览器地址栏输入一个URL背后的技术

**DNS查询过程**

1. 浏览器**解析URL**获取Web服务器和文件名，然后**生成HTTP请求报文**
   1. URL由**协议**，**域名**，**文件路径**，**端口**组成
   2. 协议默认为http，端口默认为80端口
   3. 没有路径代表访问根目录下事先设置的**默认文件**
2. **查看浏览器缓存**中是否有对应域名，如果有对应域名，则直接返回ip地址
3. 当浏览器缓存中没有对应的域名时，需要去**查看浏览器所在机器的操作系统缓存，即`hosts`文件**中是否有对应域名，如果有对应域名，则直接返回ip地址
   1. `C:\Windows\System32\drivers\etc\hosts`
   1. `/etc/hosts`
4. 当`hosts`文件中没有对应的域名时，需要由**DNS客户端**去**访问本地DNS服务器**，如果有对应域名，则直接返回ip地址
   1. TCP/IP参数中设置的首选DNS服务器
6. 本地DNS服务器缓存中如果没有对应的域名，需要去**访问13台根DNS服务器**
7. **根DNS服务器根据域名将对应授权管理的顶级DNS服务器ip地址返回给本地DNS服务器**
8. 本地DNS服务访问顶级DNS服务器，顶级DNS服务器根据域名将权威DNS服务器返回给本地DNS服务器
9. 权威DNS服务器将对应的ip地址返回给本地DNS服务器
10. 本地DNS服务器将ip返回给浏览器
11. **最终由浏览器向服务器ip发起HTTP请求**
11. 服务端响应HTTP请求，将html代码返回给浏览器
11. 浏览器浏览器解析HTML文件构建DOM树，然后解析CSS文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上
13. JavaScript的解析是由浏览器中的JavaScript解析引擎完成的
    1. JavaScript是单线程运行，在同一个时间内只能做一件事，所有的任务都需要排队


> 所以从客户端到本地DNS服务器是属于递归查询，DNS服务器之间的交互查询是迭代查询

#### 跟踪域名解析过程

```bash
# 查询域名解析结果
nslookup www.baidu.com

# 查询域名解析过程
dig www.baidu.com
dig www.baidu.com +trace
```

#### DNS缓存

DNS域名解析后会缓存解析结果

- 本地DNS服务器
- 用户本地机器

Java应用中**JVM也会缓存DNS解析结果**，是在`InetAddress`类中完成的

- 用`InetAddress`类解析域名，**必须使用单例模式**，否则会有严重的性能问题

本地DNS服务器缓存由TTL时间控制，用户本地机器可以通过刷新来清除缓存

```bash
# win
ipconfig /flushdns
# linux
/etc/init.d/nscd restart
```

## CDN

Content Delivery Network：内容分布网络

CDN是一种**流量分配网络**

- 在现在的Internet网络上增加一层新的网络架构，将网站的内容发布到最接近用户的网络**边缘**，提高用户访问网站的响应速度
  - CDN由分布在不同区域的边缘节点服务器群组成的**分布式网络**
  - CDN相当于镜像+缓存+整体负载均衡

> CDN的本质是缓存，而内核中支撑它的互联网精神则是共享
>
> CDN应用广泛，支持多种行业、多种场景内容**加速**，例如：图片小文件、大文件下载、视音频点播、直播流媒体、全站加速、安全加速

**CDN加速**

CDN的加速资源是跟域名绑定的

- 通过域名访问资源，**首先会通过DNS查找离用户最近的CDN节点**，即边缘服务器的IP
- 通过IP访问实际资源时，如果CDN上并没有缓存资源，则会**回到源站请求资源，并缓存到CDN节点上**，这样用户下一次访问时该CDN节点就有对应资源的缓存

> 淘宝的图片访问，有98%的流量都走了CDN缓存。只有2%会**回源**到源站，节省了大量的服务器资源
>
> 但是如果在用户访问高峰期，图片内容大批量发生变化，大量用户的访问就会**穿透cdn**，对源站造成巨大的压力

## HTTP

HTTP不可以使用UDP，**HTTP需要基于可靠的传输协议**，而UDP不可靠

> http3.0使用UDP实现

### http1.x 和http2.0的区别

- http1.x使用的文本（字符串）传送，http2使用**2进制传送**，解析速度更快
  - 2进制传送为多路复用提供了基础

- http1.x有**顺序**和**阻塞**约束，发送一个请求后必须等待响应后再发送下一个请求，http2支持**多路复用**，同一个连接可以**同时发送多个请求，并行传输数据，再接收响应**
  - 多路复用用长连接避免创建多个TCP连接带来的网络开销，解决了对同一域名的请求阻塞问题
- http2支持**头部（Header）压缩**
  - 对于Header中相同的数据，不会在每次通信中重新发送，而是采用**追加**或**替换**的方式
  - 在客户端和服务端之间共同维护一个Header表，存储之前发送的 key-value对。Header表在连接期间始终存在

- http1.x只能在客户端发送请求后，服务端再返回内容，http2支持**服务端主动推送**，支持在客户端未请求的情况下，主动发送内容给客户端

### HTTP的长连接与短连接

- **HTTP/1.0 默认使用的是短连接**
  - 短连接时指浏览器**每请求一个静态资源，就建立一次连接，任务结束就中断连接**
- **HTTP/1.1 默认使用的是长连接**
  - 长连接是指在**一个网页打开期间所有网络请求都使用同一条已经建立的连接**
  - 当没有数据发送时，**双方需要发检测包以维持此连接**，长连接不会永久保持连接，而是有一个保持时间
  - 实现长连接要客户端和服务端都支持长连接

> 当请求频繁时，建立和关闭TCP连接会浪费时间和带宽，而重用一条已有的连接性能更好
>
> 长连接会占用服务器的资源

### GET和POST的区别

- **GET操作是幂等的**，不会对服务器产生任何修改，所以可以对GET请求的数据做缓存
  - 幂等是指同样的请求执行一次与执行多次的效果是一样的，即f(f(x)) = f(x)
  - 这个缓存可以做到浏览器本身上（彻底避免浏览器发请求）
  - 也可以做到代理上（如nginx）
  - 所以GET请求可以被保存浏览器书签，而POST请求不能
- POST请求不是幂等的，因此结果不能缓存
- GET数据有长度限制（指URL的长度限制）
  - HTTP协议本身对URL长度并没有做任何规定，**实际的限制是由客户端/浏览器以及服务器端决定的**
  - 之所以要限制长度，是因为**服务器解析URL的时候要分配内存**
    - 对于一个字节流的解析必须分配buffer来保存所有要存储的数据
    - **URL必须当作一个整体看待，无法分块处理，所以处理一个URL请求时必须分配一整块足够大的内存**，如果URL太长，而并发又很高，就容易挤爆服务器的内存
- **GET产生一个TCP数据包，POST产生两个TCP数据包**
  - 对于GET请求，浏览器会把header和data一并发送出去，服务器响应200
    **对于POST请求，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200**
- GET可以发送的参数只能是ASCII类型，POST没有限制，甚至可以传输二进制

> 后退或刷新时，GET是无害的，POST会重新提交表单
>
> 并没有什么限制规定GET一定不能没有body，POST就一定不能把参放到URL的query上，只要请求的客户端和服务器端能够约定好
>
> REST API就是做了接口规范，通过看HTTP的method就可以明白接口是什么作用，解析格式也得到了统一

### POST是否比GET更安全

- 如果从前端安全xss csrf等来讲，POST比GET安全
  - 因为POST用body传输数据，GET用URL传输数据，更加容易被看到

- 如果从TCP协议上来讲，HTTP都是明文，都不安全
  - HTTPS则都是安全的

> 从客户端到服务器端中间有大量的节点，包括网关，代理等。它们的access log通常会记录完整的URL，比如nginx的默认access log。如果URL上携带敏感数据，就会被记录下来
>
> 私密数据在body里也是可以被记录下来的**，因此如果请求要经过不信任的公网，避免泄密的唯一手段就是HTTPS**

### Cookie与Session的区别

HTTP是**无状态协议**，之前已经认证成功的用户状态无法通过协议层保留下来，即**无法实现状态管理**

Cookie与Session都是用来跟踪**浏览器用户身份的会话方式**，一般使用Cookie来管理Session

**管理流程**

1. 客户端将ID和密码等登录信息放在请求报文的实体部分，以POST方式发送给服务器
2. **服务器发放用于识别用户的Session ID**，通过验证请求报文中的登录信息进行身份验证，然后**把用户的认证状态和Session ID绑定，然后记录在服务器端**
3. 服务器在向客户端返回响应时，会**在响应报文的首部的Set-Cookie字段内写入Session ID**
4. **客户端收到响应报文后，将Session ID作为Cookie保存在本地**。下次再向服务器发送请求时，**浏览器会自动发送Cookie，即发送了Session ID。**
5. 服务器就可以**通过Session ID来识别用户即认证状态**

**Cookie**

- **存在客户端浏览器里**，可以设置过期时间
  - 安全性较差

- 浏览器对cookie数量和大小有限制的，如果超过了这个限制，会丢失信息
  - 一个站点最多保存20个cookie

- cookie本身大小也有限制，一般是4kb
- 每次访问服务器时，浏览器会自动在首部中携带cookie

**Session**

- **存在服务端**，由服务器维护，一段时间后session就失效了
  - 安全性相对更高
  - 访问增多会占用服务器性能，考虑到服务器性能方面应当使用cookie

- **session本质上还是通过cookie实现的**
  - 浏览器的cookie中只保存一个session id，Session的信息保存在服务端，由session id标识
  - 所以如果客户端禁止cookie，那么能session也就不能用了
    - 可以手动通过URL传值、隐藏表单传递session id

> Session失效其实是服务器设置了失效时间。如果用户长时间不和服务器交互，session就会被销毁，交互的话，就会刷新session时间

### Token

当客户端频繁向服务端请求数据，服务端需要频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，并作出相应提示

Token是**服务端生成的一串字符串**，作为客户端进行请求的一个令牌

- 当客户端第一次请求登录后，服务器生成一个Token并将此Token返回给客户端
- 以后客户端只需携带这个Token前来请求数据即可，无需再用用户名和密码登录

> 减少频繁的查询数据库，减轻服务器的压力

## HTTPS

HTTP+SSL（TLS）

HTTP使用的是80端口，HTTPS使用443端口

### SSL/TLS协议

不使用SSL/TLS的HTTP通信就是不加密的通信，所有信息明文传播带来了三大风险

- **窃听风险**（eavesdropping）：第三方可以**获知**通信内容
- **篡改风险**（tampering）：第三方可以**修改**通信内容
- **冒充风险**（pretending）：第三方可以**冒充**他人身份参与通信

使用SSL/TLS协议解决这三大风险

- 所有信息都是**加密传播**，第三方无法窃听
- 具有**校验机制**，一旦被篡改，通信双方会立刻发现
- 配备**身份证书**，防止身份被冒充

**通信流程**

1. 客户端（通常是浏览器）向服务器发出加密通信的请求（ClientHello请求）
   1. 需要向服务器提供客户端生成的随机数，用于生成对话密钥
2. 服务器收到客户端请求后，向客户端发出回应（SeverHello回应）
   1. 需要向客服端提供服务器生成的随机数，用于生成对话密钥
   2. **服务器的数字证书**
3. 客户端收到服务器回应以后，首先要验证服务器证书，如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会显示警告
4. 如果证书没有问题，**客户端就会从证书中取出服务器的公钥**，向服务器发送信息
   1. 一个随机数（pre-master key），该随机数会用证书中的服务器公钥加密，防止被窃听
   2. 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送
   3. 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验
5. 服务器收到客户端的随机数（pre-master key）后，计算生成本次会话所用的会话密钥。然后，向客户端最后发送下面信息
   1. 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。
   2. 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验

> 需要将公钥放在数字证书中来保证可信
>
> 客户端与服务器进入加密通信后就完全是使用普通的HTTP协议，只不过用会话密钥加密内容

### 对称加密和非对称加密

**对称密钥加密**：共享密钥加密

- 加密解密用一个密钥
- **需要将密钥发送给对方**

**非对称密钥加密**：公开密钥加密

- 私钥自己保存
- **公钥发送给要通信的对方**

非对称密钥加密比对称密钥加密的处理速度慢，所以HTTPS采用混合加密的方式加密

- 在发送密钥的时候使用非对称密钥加密
- 在通信时使用对称加密



### 数字签名和数字证书

**数字签名**：digital signature

- 使用私钥对内容生成数字签名，发送给对方，对方用公钥解密

**数字证书**：digital certificate

- 数字签名接收方所使用的公钥可能会替换，导致不安全，别人就可以用私钥伪造数字签名

- 需要找**证书中心**（certificate authority，CA）为公钥做认证。证书中心用自己的私钥，对公钥和一些相关信息一起加密，生成数字证书
- **发送数字签名的时候附带上数字证书**，对方使用CA的公钥解密，验证是否是真的数字签名

**认证流程**

1. 客户端向服务器发出加密请求
2. 服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端
3. 客户端（浏览器）的**证书管理器**中有**受信任的根证书颁发机构列表**客户端根据这张列表，查看解开数字证书的公钥是否在列表之内
   1. 如果数字证书记录的网址与客户端正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告
   2. 如果这张数字证书不是由**受信任的机构**颁发的，浏览器会发出另一种警告
4. 如果数字证书是可靠的，客户端就可以使用**证书中的服务器公钥**，对信息进行加密，然后与服务器交换加密信息

## URL编码

由于RFC 1738规定URL只能使用英文字母、阿拉伯数字和某些标点符号，不能使用其他文字和符号，所以如果URL中有汉字，就必须编码后使用。但RFC 1738没有规定具体的编码方法，而是交给应用程序自己实现

这就导致不同的操作系统、不同的浏览器、不同的网页字符集，将导致完全不同的编码结果

- **网址路径**使用utf-8编码
- **查询字符串**使用操作系统的默认编码
- **GET和POST方法生成的URL**使用网页的编码（HTML源码中字符集设定）

解决方案

- 使用Javascript先对URL进行编码，然后再向服务器提交，不要给浏览器插手的机会
- 因为Javascript的输出总是一致的，所以就保证了服务器得到的数据是格式统一的

> 无论网页的原始编码是什么，一旦被Javascript编码，就都变为unicode字符。也即Javascipt函数的输入和输出默认都是Unicode字符

# 操作系统

## 用户态和内核态

**问题**

- **如何限制代码行为**
  - 比如禁止：设置特殊寄存器的值，访问存储器的任意位置，I/O请求，申请更多系统资源等
- 在运行这个程序的时候，**如何切换到另一个程序**
  - **进程调度应该是OS才有的权限**

**解决方法**：**引入用户态和内核态和两种模式**

- 用户态无法执行受限操作，执行这些操作会引发异常
- 内核态只能由操作系统运行，可以执行特权操作
- 用户程序通过**系统调用**执行这些特权操作
  - OS执行前会判断进程是否有**权限**执行相应的指令

**受限直接执行**：Limited Direct Execution

- 区分用户态和内核态的执行机制

### 陷入内核态

**系统调用**（trap）、**中断**（interrupt）**和异常**（exception）都会陷入内核态

- 系统调用是**用户进程主动发起**的操作
  - 进程发起系统调用
  - 陷入内核态
  - 由操作系统执行系统调用
  - 再返回到进程

- 中断和异常是被动的，**无法预测发生时机**
  - 中断包括 I/O 中断，外部信号中断，各种定时器引起的时钟中断等
  - 异常包括程序运算引起的各种错误如除0，缓冲区溢出，缺页等

在系统的处理上，中断和异常类似，都是**通过中断向量表来找到相应的处理程序进行处理**

- 区别在于**中断来自处理器外部**，不是由任何一条专门的指令造成，而**异常是执行当前指令的结果**

> C访问**访问空指针**会陷入内核态
>
> - 访问指针相当于**访问一个虚拟地址**，硬件会将虚拟地址映射到真实的物理内存
> - 如果映射失败，硬件会抛出一个**段错误异常**（`page fault exception`），此时会**从用户态转为内核态**进行处理
>   - OS会在中断向量表中找到处理`page fault exception`的中断向量，执行相应的handler

### 系统调用

System Call

- 计算机系统的各种硬件资源是有限的，在现代多任务操作系统上同时运行的多个进程都需要访问这些资源
- **为了更好的管理这些资源**，进程是不允许直接操作这些资源的，所有对这些资源的访问都必须由操作系统控制（受限直接执行）
  - 即操作系统是使用这些资源的唯一入口，**这个入口就是操作系统提供的系统调用**
- 在linux系统中**系统调用是用户空间访问内核的唯一手段**

#### 软中断

**用户空间的程序无法直接执行内核代码**，它们不能直接调用内核空间中的函数，**因为内核驻留在受保护的地址空间上**

- 如果进程可以直接在内核的地址空间上读写的话，系统安全就会失去控制

所以应用程序通过软中断的机制通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用

## 并行与并发

- 并行：parallelism
  - 多个处理器或者多核处理器**同时**处理多个不同的任务
- 并发：concurrency
  - 通过调度算法，一个处理器同时处理多个任务

## 线程

线程可以分为两类

- **用户级线程**：`user level thread`
  - 有关线程管理的所有工作都**由应用程序完成**，内核意识不到线程的存在
  - 在应用程序启动后，操作系统分配给该程序一个进程号和对应的内存空间等资源
  - 应用程序通常先在一个线程（主线程）中运行，在其运行的某个时刻，可以通过调用线程库中的函数创建一个在相同进程中运行的新线程
  - **用户级线程的优点是非常高效，不需要进入内核空间，缺点是并发效率不高**
- 内核级线程：`kernel level thread`
  - 有关线程管理的所有工作由内核完成，应用程序没有进行线程管理的代码，只能**调用内核线程的接口**
  - 内核维护进程及其内部的每个线程，调度也由内核基于线程架构完成
  - 内核级线程的优点是内核可以将不同线程更好地分配到不同的CPU，以实现真正的并行计算

> 现代操作系统往往使用组合方式实现多线程，即线程创建完全在用户空间中完成，并且一个应用程序中的**多个用户级线程被映射到一些内核级线程上**

### 协程

协程是一种**用户态的轻量级线程**

- **协程的调度完全由用户控制**

- **协程拥有自己的寄存器上下文和栈**

  - 协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈
  - 直接操作栈基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快
  - 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态

- 一个线程可以拥有多个协程，一个进程也可以拥有多个协程

- 线程进程都是同步机制，而协程则是异步

  

### 进程和线程

`Process`和`Thread`

- 进程是系统进行**资源分配**的基本单位，线程是**CPU调度**的基本单位
- 线程依赖于进程而存在，一个进程至少有一个线程
- 进程有自己的独立地址空间，**线程共享所属进程的地址空间**
- 进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源（如程序计数器PC，寄存器REG和**栈**），和其他线程共享本进程的相关资源（如内存，堆，I/O，CPU等）
- 在进程切换时，涉及到整个**当前进程CPU环境**的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作
  - **进程切换的开销远大于线程切换的开销**
- 线程之间的通信更方便，同一进程下的线程**共享全局变量等数据**，而进程之间的通信需要以进程间通信（IPC）的方式进行
- **多线程程序**只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为**进程有自己的独立地址空间**
  - 多进程更加健壮

> 进程切换开销太大，因此引入线程



### 浏览器开一个标签页是创建进程还是线程

Chrome界面内的每个标签页都是一个进程，其它浏览器的每个标签页都是一个线程

- 安全性：相比于线程，进程之间是不共享资源和地址空间的，所以不会存在太多的安全问题
  - 多个线程共享着相同的地址空间和资源，所以会存在线程之间有可能会恶意修改或者获取非授权数据的可能

- 健壮性：由于多个线程共享同一个进程的地址空间和相关的资源，所以当一个线程出现crash，可能会导致相应的地址空间和资源会出现问题，从而导致其它的线程也crash
  - 当一个标签页突然崩溃时，所有的标签页都会崩溃，这时通常浏览器要重启（重启进程，重新生成线程)
  - 而多进程则不存在这个问题, 因为不同的地址空间和资源，当一个进程崩溃时不会影响到其它进程

- 性能：进程的安全性和健壮性是建立在独立的地址空间和独立的资源的条件下的，所以进程的启动，关闭和切换相比于线程会有更多的开销

一般情况下，每打开一个浏览器标签页，会新开一个独立进程，即使两个标签页打开的是同一个页面

- 如果是通过一个标签页打开另一个标签页时，Chrome可能会将两个标签页共用一个进程

**一个标签页对应的进程是多线程的**

- GUI渲染线程
- JavaScript引擎线程
- 异步http请求线程

> 打开任务管理器查看，显示的进程，浏览器Chrome进程旁边会有个数字，点击会展开一个列表

## 进程通信

**进程间通信是实现进程同步的手段**

- 共享内存（Shared Memory）
- 消息队列（MQ：Message Queue）
- 管道（Pipe）
- 命名管道
- 信号（Signal）
- 信号量（Semaphore）
- 套接字（Socket）

### 信号

信号是Linux系统**响应某些条件而产生的一个事件**，是一种**更高层的**软件形式的异常，一个信号代表了一个消息

- 信号的作用是用来**通知进程**发生了某种系统事件，是一种**订阅-发布**的模式

- 由操作系统事先定义，**接收到该信号的进程可以采取自定义的行为**

**信号来源**

- 硬件来源：如按下`CTRL+C`、除0、非法内存访问等
- 软件来源：如`kill`命令、Alarm Clock超时、当Reader中止之后又向管道写数据等

> `kill -9`

**一般的信号是都是由一个错误产生的**

- 除数为0时会引发0号中断，即除零异常，这是一个硬件级中断，会导致陷入内核，执行操作系统预定义在 IDT中的中断处理程序

- 操作系统**处理这个异常的方法就是向进程发送一个信号** `SIGFPE`。如果进程设置了相应的signal handler，就执行进程的处理方法。否则就执行操作系统的默认操作（一般这种信号的默认操作是杀死进程）

> 操作系统会**将这些硬件异常包装成信号发送给进程**，如果进程不处理这几个异常信号，默认的行为就是挂掉

**进程发送信号**

- 操作系统提供发送信号的**系统调用**
- 发送信号时，必须指明发送的目标进程的PID
  - 一般用在具有**亲缘关系的进程之间**
- 系统调用会**将信号放到目标进程的信号队列中**
  - 如果目标进程未处于执行状态，则该**信号就由内核保存**起来，直到该进程恢复执行并传递给它为止
  - 如果一个**信号被进程设置为阻塞**，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程

**进程接收信号**

- 每个进程有一个信号队列，存放**其他进程发送给它，等待它处理的信号**
- 进程在执行过程中的**特定时刻检查并处理自己的信号队列**
  - 如从系统空间返回到用户空间之前

**用户进程对信号的处理**

- 处理信号

  - 定义**信号处理函数**，当信号发生时执行相应的处理函数
- 忽略信号

  - 当不希望接收到的信号对进程的执行产生影响时，可以忽略该信号，不对信号进程作任何处理，从而让进程继续执行时
- 不处理也不忽略

  - 执行默认操作，linux系统对每种信号都规定了默认操作
- 有些信号用户进程是无法处理也无法忽略的（如`SIGSTOP`、`SIGKILL` 等）

### 管道

管道是一种**半双工的通信方式**，数据只能**单向流动**

- 上游进程往管道中写入数据，下游进程从管道中接收数据
- 如果想实现双方通信，那么需要建立两个管道

- 管道发送的内容是**没有格式的字节流**，适合于**传输大量信息**

**管道同步**

操作系统会保证**读写进程的同步**

- 管道就相当于一个文件，**同一时刻只能有一个进程访问**
  - 下游进程或者上游进程需要**等另一方释放锁后才能操作管道**。
    - 当管道为空时，下游进程读阻塞
    - 当管道满时，上游进程写阻塞

> 在 Linux Shell 中经常使用管道操作符`|`来表示两个命令之间的数据通信
>
> - 管道操作符`|`的内部实现就是Linux的管道接口
> - 由管道操作符`|`分割的**每个命令是独立的进程**，各个进程的标准输出`STDOUT`，会作为下一个进程的标准输入`STDIN`

**创建管道**

Linux管道包含**匿名管道**和**命名管道**，管道文件信息保存在内存里

- 通过 `pipe()` 系统调用来创建并打开一个**匿名管道**
- **匿名管道只能用于具有亲缘关系的进程之间**
  - 父子进程或兄弟进程
- 命名管道可以用于并不相关的进程之间

> 当管道不再被任何进程使用时会自动消失

**实现管道**

- **管道就是一个文件**
  - 一种**只存在于内存中**的特殊的文件系统
- 在Linux中管道借助了**文件系统的File结构**实现
  - 父进程使用File结构保存向管道写入数据的例程地址，子进程保存从管道读出数据的例程地址（单向流动，亲缘进程）
- 管道是由内核管理的一个**环形的数据结构缓冲区**，以便管道可以被循环利用（循环队列）

### 命名管道

`FIFO`

- 命名管道是一种**全双工的通信方式**
- 命名管道可用于没有亲缘的进程间
- 通过 `mknode()` 系统调用或者 `mkfifo()` 函数创建命名管道
  - 任何有访问权的进程都可以**通过文件名将其打开和进行读写**，而不局限于亲缘进程
- 创建命名管道时会**在磁盘中创建一个索引节点**，命名管道的名字就相当于**索引节点的文件名**
  - 索引节点设置了**进程的访问权限**，但是没有数据块
- **命名管道实质上也是通过缓冲区来实现数据传输**
  - 有访问权限的进程可以通过磁盘的索引节点来读写这块缓冲区
- 当不再被任何进程使用时命名管道在内存中释放，但磁盘节点仍然存在

### 信号量

信号量是一种特殊的变量，**对它的操作都是原子的**

- 在Linux系统中，二进制信号量又称**互斥锁**`Mutex`，可以用于实现进程或线程的互斥和同步
- 信号量在底层的实现是**通过硬件提供的原子指令**，如`Test And Set`、`Compare And Swap`等

> V：`signal()`，P：`wait()`
>
> - `V(S)`：如果有其他进程因等待S而被挂起，就让它恢复运行，否则S加 1
>
> - `P(S)`：如果S<=0，则挂起进程，否则S减1

### 共享内存

允许多个进程共享**同一块物理内存**，**不同进程可以将同一段共享内存映射到自己的地址空间，然后像访问正常内存一样访问它**

- 共享内存区只会驻留在创建它的进程地址空间内
- 不同进程可以通过向共享内存端读写数据来交换信息

**优点**

**简单且高效**：访问共享内存区域和访问进程独有的内存区域一样快

- 不需要系统调用，不涉及**用户态到内核态的转换**
  - 只在建立共享内存区域时需要系统调用
  - 建立共享内存后所有访问都可作为**常规内存访问**，无需借助内核
- 不需要对数据不必要的复制

**缺点**

**存在并发问题**：有可能**多个进程同时修改同一块内存**

- 因此共享内存一般与信号量结合使用

> Linux2.2.x内核支持多种共享内存方式
>
> - `mmap()`系统调用
>   - 将**普通文件**映射到进程的地址空间，然后可以像访问普通内存一样对文件进行访问，不必再调用`read()`，`write()`等操作
>   - `mmap()`不是专门用来共享内存的，但是多个进程可以通过`mmap()`映射同一个普通文件来实现共享内存
> - 系统V
>   - 通过**映射特殊文件系统shm中的文件**实现进程间的共享内存
>   - 通过`shmget`可以创建或获得共享内存的标识符，取得共享内存标识符后，通过`shmat`将这个内存区映射到本进程的虚拟地址空间

### 消息队列

消息队列是一个**消息的链表**，**保存在内核中**

- 消息队列中的**每个消息都是一个数据块，具有特定的格式**
- 操作系统中可以存在多个消息队列，每个消息队列有唯一的`key`，称为消息队列标识符
  - 操作系统提供创建消息队列、取消息、发消息等系统调用
  - 操作系统负责**读写同步**
    - 若消息队列已满，则写消息进程排队等待
    - 若取消息进程没有找到需要的消息，则在等待队列中寻找
- 消息队列是**异步的**
  - 消息队列允许一个或多个进程向它写入和读取消息
  - 消息的发送者和接收者**不需要同时与消息队列交互**，消息会保存在队列中，直到接收者取消息

**优点**

消息队列克服了**信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限**等缺点

- 和信号相比，消息队列能够传递更多的信息
- 与管道相比
  - 消息队列提供了**有格式的数据**
  - 取消息进程**可以选择接收特定类型的消息**，而不像管道默认全部接收

**缺点**

- 消息队列仍然有大小限制
- 消息队列是**异步的**，所以接收者必须**轮询**消息队列才能收到最近的消息

### 本地套接字

**不同的计算机的进程**之间通过socket通信

- 也可用于同一台计算机的不同进程

- 需要通信的进程之间首先要**各自创建一个socket**，声明自己接收来自端口的数据
  - 内容包括主机地址与端口号（`ip:port`）
- 进程通过socket把消息发送到网络层中，网络层通过主机地址将其发到目的主机，**目的主机通过端口号发给对应进程**

- 操作系统提供创建socket、发送、接收的系统调用
  - 为每个socket设置**发送缓冲区**，**接收缓冲区**

## 进程调度

线程是CPU调度的最小单位

**批处理系统**

- 先来先服务：first-come first-serverd（FCFS）
  - 非抢占式，开销小，无饥饿问题

- 短作业优先：shortest job first（SJF）
  - 非抢占式，开销可能较大，可能导致饥饿问题

- 最短剩余时间优先：shortest remaining time next（SRTN）
  - 短作业优先的抢占式版本
- 最高响应比优先：Highest Response Ratio Next（HRRN）

**交互式系统**

- 时间片轮转：Round Robin
  - 抢占式，开销小，无饥饿问题
- 优先级调度算法：Priority
- 多级反馈队列调度算法：Multilevel Feedback Queue

### 操作系统怎么来停止一个进程

## 线程调度

- **协同式线程调度**：线程的执行时间以及线程的切换都是由**线程本身来控制**，线程把自己的任务执行完后，主动通知系统切换到另一个线程
  - 优点是没有线程安全的问题，缺点是线程执行的时间不可控，可能因为某一个线程不让出CPU，而导致整个程序被阻塞
- **抢占式调度模式**：线程的执行时间和切换都是由**系统来分配和控制**，不过可以通过设置线程优先级，让优先级高的线程优先占用CPU
  - JVM默认采用抢占式调度模型

## 进程分类

- 僵尸进程：停止运行
- 孤儿进程：正在运行
- 守护进程：正在运行

### 僵尸进程

僵尸进程是指**终止但还未被回收**的进程

- 当一个进程由于某种原因终止时，**内核并不是立即把它从系统中清除**。
- 进程会保持在一种**已终止**的状态中，直到被它的**父进程回收**。当父进程回收已终止的子进程时，内核会抛弃已终止的进程，此时该进程就不存在了
- 如果子进程退出，而父进程并没有调用 `wait()` 或 `waitpid()` 来回收，那么就会产生僵尸进程
- 僵尸进程是一个已经死亡的进程，但是其**进程描述符**仍然保存在系统的进程表中
- 如果杀死父进程，僵尸进程就会变成孤儿进程，由`Init`进程接管并处理

**危害**

- 占用进程号
  - 系统所能使用的进程号是有限的，可能导致不能产生新的进程
- 占用一定的内存

### 孤儿进程

如果某个进程的**父进程先结束了**，那么它的子进程会成为孤儿进程

- 每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用`Init`进程（`pid = 1`）接管，并由`Init`进程调用 `wait` 等待其结束，完成状态收集工作。
- **孤儿进程不会对系统造成危害**

### 守护进程

守护进程：daemon

- 一种**在后台执行**的电脑程序，此类程序会被以进程的形式初始化

## 进程同步

- **临界资源**：可以为若干线程所共享，但一次只能为一个线程所利用的**资源**
- **临界区**：访问临界资源的**程序片段**，当有线程进入临界区时，其他线程或是进程必须等待
  - 有一些同步机制必须在临界区的进入点与离开点实现，以确保这些共用资源是被互斥获得使用

### 死锁

`DeadLock`

**两个或多个进程**才有可能出现死锁

- 一个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，若无外力作用它们都将无法推进下去，称这一组进程产生了死锁

> 相互等待，无限期阻塞的一种状态

**死锁产生的四个必要条件**（有一个条件不成立都不会产生死锁）

- 互斥条件：一个资源一次只能被一个进程使用
- 请求与保持条件：一个进程因请求资源而阻塞时，**对已获得资源保持不放**
- 不剥夺条件：进程获得的资源，在未完全使用完之前，**不能强行剥夺**
- 循环等待条件：若干进程之间形成一种头尾相接的**环形等待资源关系**

**解决死锁的基本方法**

- 破坏四个必要条件
  - **互斥条件无法被破坏**
  - 破坏请求与保持条件实现起来困难，会降低系统性能
  - 破坏不剥夺条件：需要采取**资源预先分配策略**
    - 一次性地向系统申请它所需要的全部资源。如果某个进程所需的全部资源得不到满足，则不分配任何资源，此进程暂不运行。只有当系统能够满足当前进程的全部资源需求时，才一次性地将所申请的资源全部分配给该进程
    - 资源利用率低，降低了进程的并发性
  - 破坏循环等待条件：需要采取**资源有序分配策略**
    - 把资源事先分类编号，按号分配，所有进程对资源的请求必须严格按资源序号递增的顺序提出，进程占用了小号资源，才能申请大号资源，就不会产生环路
- 避免死锁发生
  - 动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配
  - 银行家算法：找出安全分配的进程序列
- 解决发生的死锁
  - 利用抢占：挂起某些进程，并抢占它的资源。但要防止某些进程被长时间挂起而处于饥饿状态
  - 利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点
  - 利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行

**检测死锁**

- 等待图（wait-for graph）：采用深度优先搜索的算法实现，如果图中有环路就说明存在死锁

## 内存管理

### 寻址

### 虚拟内存

### 页面置换算法

### 请求换页过程

## 文件

- 文件描述符在形式上是一个非负整数，**它是一个索引值**，指向内核为每一个进程所维护的该**进程打开文件的记录表**
- 当程序打开一个现有文件或者创建一个新文件时，**内核向进程返回一个文件描述符**，内核通过文件描述符来访问文件

## IO

### 磁盘IO

**因为磁盘设备是操作系统管理的，所以读取和写入文件IO操作都是调用操作系统提供的接口**

- `read()`和`write()`系统调用
- **数据需要从磁盘复制到内核空间，再从内核空间复制到用户空间**

**内核缓存**

- 操作系统为了加速IO访问，在内核空间使用缓存机制，**用户程序访问同一段磁盘地址时，直接返回内核缓存的数据**

#### 标准访问文件

- 调用`read()`，操作系统查看内核缓存是否有数据，没有就从磁盘读取
- 调用`write()`，将数据从用户空间复制到内核空间的缓存中，由操作系统决定何时写到磁盘中，或使用`sync()`同步到磁盘中

#### 直接IO方式

- 应用程序直接访问磁盘，**不经过操作系统内核数据缓冲区**，减少一次从内核空间复制到用户空间的开销

#### 内存映射方式

- 操作系统将内存的某一块区域和磁盘的文件关联起来，这两个空间的数据是共享的，减少一次从内核空间复制到用户空间的开销

### 网络IO

**CPU处理数据的速度远远大于IO准备数据的速度**

> 网络IO的耗时跟磁盘IO差不多，大部分web应用的性能瓶颈都是IO瓶颈

**IO模型**

- **同步IO模型**
  - 阻塞IO（BIO：Blocking IO）
  - 非阻塞IO（NIO：Non-Blocking IO）
  - **IO多路复用**
  - 信号驱动IO
- **异步IO模型**
  - AIO
  - IOCP

#### Socket

- Socket是在应用层和传输层中间的**抽象层**
  - 它把传输层（TCP/UDP）的复杂操作抽象成一些简单的接口，**供应用层调用实现进程在网络中的通信**
- Socket起源于Unix，Unix中一切皆文件，**在内核中Socket也是以文件的形式存在的**，有对应的文件描述符

  - Socket是一种**打开—读/写—关闭**模式的实现
- 服务器和客户端各自维护一个**文件**，在建立连接打开后，可以向文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件
- Socket设计的目的和想要解决的问题就是把网卡中的网络数据识别出来是给哪个进程的，并持续和稳定地给到对应的应用进程

> Socket一般被翻译为套接字，其实它在英文的含义为插座，Socket就像一个插座，负责连通两端，进行点对点通信
>
> - 端口就像插座上的孔，端口不能同时被其他进程占用
> - 建立连接就像把插头插在这个插座上，创建一个Socket实例
> - 开始监听后，这个插座就时刻监听着消息的传入，谁拨通IP和端口，就接通谁

##### 处理请求

操作系统**内核通过网卡读取网络数据**，将网络数据存储在内存中

1. **内核通过网卡将数据复制到内核缓冲区**
   1. 内核会通过**DMA技术**控制IO是否阻塞
2. **用户进程再将数据从内核缓冲区复制到用户空间处理**
   1. 通过**mmap内存映射**控制IO是否同步
      1. mmap内存映射是指**用户空间和内核空间映射同一块内存空间**
      2. 从而省略将数据从内核缓冲区拷贝到用户空间的操作，**用户空间通过映射直接操作内核缓冲区的数据**

##### Socket通信过程

1. 服务端首先调用`socket()`函数，**创建一个Socket**
   1. 其中网络协议为IPv4，传输协议为TCP 
2. 服务端调用`bind()`函数，**给这个Socket绑定一个IP地址和端口**
   1. 绑定端口：内核收到TCP报文后通过TCP头里面的端口号找到应用程序，然后传递数据
   2. 绑定IP地址：一台机器可以有多个网卡，**每个网卡对应一个IP地址**，绑定一个网卡的IP地址后，内核才能收到该网卡上的数据
3. 服务端调用`listen()`函数**对这个Socket进行监听**
   1. 可以通过`netstat`命令查看对应的端口号是否有被监听来**判断服务器中的某个应用程序有没有启动**
   1. Socket对应的数据结构中会包含指定监听的端口和包含监听ip地址的通配符，通常情况通配符是`*`，表示监听所有地址
4. 服务端进入了监听状态后，通过调用`accept()`函数**从内核获取来自客户端的连接请求**
   1. 调用`accept()`函数会进入阻塞状态，如果没有客户端请求连接，则**会一直阻塞等待客户端连接的到来**
5. 客户端也调用`socket()`函数，**创建一个Socket**，然后调用`connect()`函数向服务端发起连接
   1. **开始TCP三次握手**
   2. `connect()`函数的参数会指明服务端的IP地址和端口号

6. 服务端的`accept()`函数在获取连接后会**返回用于传输的Socket的文件描述符，后续用这个Socket来传输数据**
   1. **监听的Socket和真正用来传数据的Socket是两个不同的Socket**
7. 客户端和服务端使用`write()`函数和`read()`函数向服务端请求和发送数据

##### Socket队列

在TCP连接的过程中，**服务端内核实际上为每个Socket维护了两个队列**

- **TCP半连接队列**：还没完全建立连接的队列，这个队列都是没有完成三次握手的连接
- **TCP全连接队列**：已经建立连接的队列，这个队列都是完成了三次握手的连接

当**TCP全连接队列**不为空后，服务端的`accept()`函数会从内核中的TCP全连接队列里拿出一个已经**完成连接的Socket**返回应用程序，后续数据传输都用这个Socket

##### Accept()函数在TCP三次握手的那一部分开始，哪一部分返回

服务端调用`listen()`函数进行监听，然后使用`accept()`函数等待请求（**阻塞等待**），客户端通过`connect()`函数发起请求

- 第一次握手：客户端发送syn包到服务器
  - `accept()`函数被阻塞
  - `connect()`函数被阻塞
- 第二次握手：服务器收到syn包，确认客户端的SYN，然后发送ack包到客户端
  - `accept()`函数被阻塞
  - `connect()`函数被阻塞
- 第三次握手：客户端收到syn包和ack包，发送ack包到服务器
  - `accept()`函数被阻塞
  - `connect()`函数完成建立连接的功能

服务端收到ack包，**三次握手完成，TCP连接建立，服务器调用`accept()`函数获得返回的连接**，所以是在第三次握手后

##### 服务器单机理论最大能连接的客户端数目

TCP连接由四元组唯一确认：**本机IP, 本机端口, 对方IP, 对方端口**

- 服务器的IP和端口是固定的，四元组只有对方IP和端口会变化，所以**最大TCP连接数 = 客户端IP数×客户端端口数**
- 对于IPv4，客户端的IP数最多为2<sup>32</sup>次方，客户端的端口数最多为2<sup>16</sup>次方，所以理论上**服务端单机的最大TCP连接数约为2<sup>48</sup>**
- 但Socket实际上是一个文件，会对应一个文件描述符。在Linux下，**单个进程打开的文件描述符数是有限制的**，没有经过修改的值一般都是1024
- **每个TCP连接在内核中都有对应的数据结构**，即每个连接都是会占用一定内存

#### 同步IO

上述Socket调用使用的是**同步阻塞（BIO）的方式，只能一对一通信**

- 当服务端在还没处理完一个客户端的网络I/O 时，或者读写操作发生阻塞时，其他客户端是无法与服务端连接的

> 进程从调用到返回这段时间内都是被阻塞的称为阻塞IO，否则就是非阻塞IO

##### 同步阻塞IO

- 应用进程调用`recv()`系统调用，**等待数据时一直阻塞**，直到内核数据拷贝到用户空间

##### 同步非阻塞IO

- 应用进程一直**轮询调用`recv()`系统调用查看内核缓冲区的数据是否准备好**，内核立即给予答复，**进程不会阻塞**
- 如果内核通知数据还未准备好，则应用进程接着轮询
- 系统调用带来的来回的**用户态和内核态的切换**导致成本几何上升

##### IO多路复用

`IO Multiplexing`

只使用一个进程来处理多个网络连接（维护多个Socket），就是**I/O多路复用**技术，也叫**事件驱动IO**

- 由OS提供`select()`，`poll()`，`epoll()`三个系统调用函数**不断轮询进程所负责的所有Socket**
  - 即单个处理的线程只受阻于select()调用，由内核去轮询查看某一个Socket是否有数据到达
- 当某个Socket有数据到达了（数据状态准备就绪），就通知用户进程处理数据

> Recv 只能监视单个 Socket，为每个请求连接分配一个进程/线程的方式开销太大

**思想**

- 类似于一个CPU并发多个进程，用切分时间片的方式**让多个请求复用一个进程**
- 只需要一个或几个线程就可以完成**数据状态询问**的操作，当有数据准备就绪之后再分配对应的线程去读取数据



##### select，poll，epoll

select和poll是线程不安全的，epoll是线程安全的

**select**

预先传入一个Socket列表，如果列表中的Socket都没有数据，挂起进程，直到有一个Socket收到数据，唤醒进程

- 将所有Socket的文件描述符放入一个集合中
  - 集合大小有限制，32位机默认是1024（64位：2048）
- 调用`select()`时，**将Socket集合从用户空间拷贝到内核空间**，由内核根据文件描述符的就绪状态修改该集合的内容
  - 每次都要复制，开销大
- 采用水平触发机制（LT，Level Trigger）
- `select()`返回后，**进程需要通过遍历这个集合找到就绪的文件描述符**
  - 当文件描述符的数量增加时，轮询的方式效率较低

**poll**

- 和`select()`的区别在于文件描述符的存储方式不同
  - **poll采用链表的方式存储，没有最大存储数量的限制**


**epoll**

- **通过内核和用户空间共享内存**，避免了不断复制的问题
- 支持的同时连接数上限提高（1G左右的内存支持10W左右的连接数）
- **文件描述符就绪时采用回调机制，避免了轮询**
  - 回调函数**将就绪的描述符添加到一个链表中**，执行`epoll_wait`时，返回这个链表
  - 不用用户程序自己再去进行遍历查询
- 支持水平触发和边缘触发（ET，Edge Trigger），采用边缘触发机制时，**只有活跃的文件描述符才会触发回调函数**
- epoll这个系统调用对外部来说，是一个同步的接口，必须等待操作系统返回值

> epoll通过红黑树来组织所有监控的socket对象，实现高效的查找，删除和添加
>
> epoll系统调用依旧是同步的，必须等待操作系统返回值
>



## Copy-on-write

`Copy-on-write`：COW，写时复制，也称为隐式共享（implicit sharing）

- **将复制操作推迟到第一次写入时**进行
  - 在创建一个新副本时，不会立即复制资源，而是**共享原始副本的资源**，当修改时再执行复制操作
- 通过这种方式共享资源，可以显著减少创建副本时的开销，以及节省资源

> 主要在很多情况下根本不需要复制，就节省了大量时间，充分使用了稀有的物理内存
>
> 但如果在子进程存在期间发生了大量写操作，那么会频繁地产生页面错误，不断陷入内核来复制页面，反而会降低效率

### 为什么需要COW

当通过`fork()`系统调用来创建一个子进程时，**操作系统需要将父进程虚拟内存空间中的大部分内容全部复制到子进程中**

- 主要是数据段、堆、栈；代码段共享
- 这个操作不仅非常耗时，而且会浪费大量物理内存
- 如果程序在进程复制后立刻使用`exec`加载新程序，那么负面效应会更严重，相当于之前进行的**复制操作是完全多余的**

因此引入了COW技术

- 内核不会复制进程的整个地址空间，而是**只复制进程的页表**，`fork()`之后的**父子进程的地址空间指向同样的物理内存页**
- 不同进程的内存空间应当是**私有**的，假如所有进程都只读取其内存页，那么就可以**继续共享物理内存中的同一个副本**。但是只要有一个进程试图写入共享区域的某个页面，那么就会**为这个进程创建该页面的一个新副本**

### 原理

- `fork()`之后，内核会**把父进程的所有内存页都标记为只读**。一旦其中一个进程尝试写入某个内存页，就会**触发一个保护故障（缺页异常）**，此时会陷入内核
- **内核将拦截写入**，并为尝试写入的进程**创建这个页面的一个新副本，恢复这个页面的可写权限**，然后重新执行这个写操作，这时就可以正常执行了

- **内核会保留每个内存页面的引用数**。每次复制某个页面后，该页面的引用数减少一。如果该页面只有一个引用，就可以跳过分配，直接修改

> 这种分配过程对于进程来说是透明的，能够确保一个进程的内存更改在另一进程中不可见

### 应用

Redis的持久化机制中，如果采用`bgsave`或者`bgrewriteaof`命令，就会 `fork()`一个子进程来**将数据存到磁盘中**

- Redis的读取操作多，这种情况下使用COW可以减少`fork()`操作的阻塞时间

## 零拷贝

## 堆和栈的区别

**栈（stack）**

由编译器自动分配和自动释放 ，存放函数的参数值，局部变量的值等

- 只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出
- 栈是向低地址扩展的数据结构，是一块连续的内存的区域。所以栈顶的地址和栈的最大容量是系统预先规定好的（编译时就确定的常数），能从栈的空间较小
- 函数调用时第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址，然后是函数的各个参数，然后是函数中的局部变量
  - 在大多数的C编译器中，参数是由右往左入栈的
  - 静态变量是不入栈的
- 函数调用结束后，局部变量先出栈，然后是函数的各个参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行

**堆（heap）**

一般由程序员申请分配和手动释放， 若程序员不释放，程序结束时可能由OS回收

- C中malloc函数和Java中new函数
- OS有一个记录空闲内存地址的链表，当系统收到程序的申请时，
  会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序
  - 大多数OS会在这块内存空间中的首地址处记录本次分配的大小，到时候才能正确的释放这块内存空间
- 堆是向高地址扩展的数据结构，是不连续的内存区域，OS用链表来存储空闲内存地址的（链表的遍历方向是由低地址向高地址）堆的大小受限于OS有效的虚拟内存，所以堆的空间比较灵活，也比较大
- 一般在堆的头部用一个字节存放堆的大小



# Linux

## 查看CPU使用率、内存、磁盘、进程端口

### top

`top`：显示当前系统**正在执行的进程**的相关信息，包括进程ID、内存占用率、CPU占用率等

- 进程数
  - running，sleeping

- 进程占用CPU的使用
- 进程使用的物理内存和总内存的百分比

`load average`字段：CPU使用率

- 由逗号分割的3列数字分别代表了最近1分钟，5分钟，15分钟**CPU的平均负载**情况

- 单核CPU的话，1.00就表示CPU已经满负荷了。多核CPU的话，load average达到CPU的核数即说明已经满负荷了。多颗物理CPU，则load average达到所有物理CPU的总核数时，说明已经满负荷了。

### free

查看节点的内存使用情况基本上都是使用`free`命令，输出会显示系统内存的使用情况，包括**物理内存**、**交换内存（swap）**和**内核缓冲区内存**等

**行**

- `Mem`：内存的使用情况
- `Swap`：交换空间的使用情况

**列**

- `total`：显示系统总的可用物理内存和交换空间大小
- `used`：显示已经被使用的物理内存和交换空间
- `free`：显示还有多少物理内存和交换空间可用使用
- `shared`：显示被共享使用的物理内存大小
- `buff/cache`：显示被buffer和cache使用的物理内存大小
- `available`：显示还可以被**应用程序**使用的物理内存大小

### df

**disk free**

`df -h`：查看磁盘使用情况

- 文件系统
- 容量使用
- 挂载点

### ps

**process status**

`ps –ef`：查看进程的状态

- UID
- PID

> `ps -ef | grep tomcat`
>
> `kill pid`

## 如何查看某个端口是否被占用

`lsof -i :port`

- 列出谁在使用某个端口，显示pid

`netstat -anp | grep  port`

- 主要看监控状态：`LISTEN`表示已经被占用，最后一列显示占用的服务，对应具体端口号
  - 显示`LISTENING`并不表示端口被占用

`netstat -nultp`

- 查看当前**所有已经使用**的端口情况，状态都是`LISTEN`

### 查看磁盘空间使用情况

`df -h`

### 查看根目录下每个文件夹的大小

`du -sh *`

- `-s`：显示当前目录的总和
- `-h`：使用K，M，G来显示使用量 

### 删除7天前占用磁盘过高的文件

### 如何在/usr目录下找出大小超过10MB的文件

`find /usr -type f -size +10240k`

### 如何在/var目录下找出90天之内未被访问过的文件

`find /var ! -atime -90`

### 如何在/home目录下找出120天之前被修改过的文件

`find /home -mtime +120`

### 删除n天前的旧文件

`find dir -mtime +days -name fileName -exec rm -rf {} \;`

```bash
# 将/usr/local/backups目录下所有10天前带"."的文件删除
find /usr/local/backups -mtime +10 -name "*.*" -exec rm -rf {} \;
# -mtime：标准语句写法
# ＋10：查找10天前的文件，这里用数字代表天数，＋30表示查找30天前的文件
# "*.*"：希望查找的数据类型，"*.jpg"表示查找扩展名为jpg的所有文件，"*"表示查找所有文件
# -exec：固定写法
# rm -rf：强制删除文件，包括目录
# {} \; ：固定写法，大括号+空格+\+;
```

## 屏幕输出hello的流程

## Kill命令

在Linux中**终止一个进程**有两种方式

- 前台进程可以使用`Ctrl + C`进行终止
- 后台进程需要使用`kill`命令来终止

`kill [参数] [进程号]`

- `-l`：信号，若果不加信号的编号参数会列出全部的信号名称
- 信号如果没有指定的话，**默认会发出终止信号，即15**

> `kill`命令只用于像进程发送一个命令

**常用信号**：`SIG`

- HUP：1，终端断线
- **INT：2，中断信号，等价于`Ctrl + C`**
- QUIT：3，退出，等价于`Ctrl + \`
- TERM：15，终止信号
- **KILL：9，强制终止信号**
- CONT：18，继续，与STOP相反
- STOP：19，暂停，等价于`Ctrl + Z`

### kill -9 和 kill -15的区别

`SIGTERM`

当使用`kill -15`时，系统会发送一个`SIGTERM`的信号给对应的程序，**当程序接收到该信号后，具体要如何处理是自己可以决定的**

- 立即停止程序
- 释放响应资源后停止程序
- **忽略该信号，继续执行程序**

即`kill -15`信号只是通知对应的进程**要进行安全、干净的退出**，程序接到信号之后，退出前一般会进行一些准备工作

- 如资源释放、临时文件清理等等，准备工作做完了再进行程序的终止

但如果在准备工作进行过程中，遇到阻塞或者其他问题导致无法成功，**那么应用程序可以选择忽略该终止信号**

> 这就是为什么有的时候使用`kill`命令是没办法杀死应用的原因，即`kill`命令是不一定一定能终止一个进程的，因为进程可能会忽略这个信号，但`KILL`信号（9）永远不会被忽略
>
> 但有一些进程连`KILL`信号（9）都不能影响到他们（IO问题造成 ），只能通过重启系统来解决

`SIGKILL`

- 使用`kill -9`时，系统会发出`SIGKILL`信号，要求接收到该信号的程序**立即结束运行，不能被阻塞或者忽略**

- 所以应用程序是没有时间进行准备工作的，这通常会带来一些副作用，**如数据丢失或者终端无法恢复到正常状态等**

### Java如何处理SIGTERM信号

在Linux中，Java应用程序是作为一个独立进程运行的，**Java应用程序的终止运行是基于JVM的关闭实现的**

JVM关闭方式分为3种

- **正常关闭**：当最后一个非守护线程结束或者调用了`System.exit`或者通过其他特定平台的方法关闭
  - 接收到`SIGINT(2)`、`SIGTERM(15)`信号等
- **强制关闭**：通过调用`Runtime.halt`或者是在操作系统中强制关闭
  - 接收到`SIGKILL(9)`信号
- **异常关闭**：运行中遇到`RuntimeException`异常等

JVM进程在接收到`SIGTERM(15)`信号的时候，可以做一些清理动作，比如删除临时文件等

- 开发者也可以自定义一些额外动作，比如让tomcat容器停止，让dubbo服务下线等
- 自定义JVM清理动作的方式是通过JDK中提供的`shutdown hook`实现的
- JDK提供了`Java.Runtime.addShutdownHook(Thread hook)`方法，可以注册一个JVM关闭的钩子

> 使用`kill -9`强制关闭进程的时候，程序就不会执行`shutdownHook`，而是直接退出，并且会给出一个提示：`interrupted by signal 9: SIGKILL`

## /PROC

`/proc`目录下存放着**内核有关系统状态**的各种有意义的信息

- 在系统运行时，内核会随时向这个目录下写入数据
- `top`和`ps`就是从这里读取数据的
  - `ps`从`/proc/stat`目录中读信息
- 这也是OS向用提供的一条通往内核的通道
  - 用户甚至可以向这个目录下的文件写入数据来修改操作的参数

**目录中内容**

- 每个进程对应一个目录，目录名就是PID
  - `init`进程PID为1，由内核在系统启动时创建，所在目录即`/proc/1`

## 文件系统

### 文件类型

查看文件类型：`ls -l`

显示的**第一个字符就是文件类型**

- 普通文件：`-`
- 目录：`d`
- 字符设备文件：`c`
- 块设备文件：`b`
- 本地域套接口文件：`s`
- 具名管道：`p`
- 符号链接：`l`

**两类设备文件**

- **字符设备文件**
  - **顺序访问设备**，必须按数据发送顺序从串行线路上获取
  - 从其中读取字符序列的设备，如磁带和串行线路
- **块设备文件**
  - **随机访问设备**，可以从硬盘的任何随机位置获取数据
  - 指用来存储数据并对其部分内容提供同等访问权的随机访问设备，如磁盘

### 查看文件

#### cat，tac，more，less，head，tail

`cat`：concatenate，查看文件内容，从第一行开始

- 连接文件并**打印全部内容到标准输出设备上**（屏幕）

`tac`：查看文件内容，从最后一行开始显示

- 倒着写的`cat`

`more`：一页一页的查看文件内容

- `space`：向下翻**一页**
- `Enter`：向下翻n行（默认**一行**）
- `b`：向上翻一页（只对文件有用）
- `q`：退出

`less`：一页一页的查看文件内容，比`more`的功能更多

- 使用光标在文件（前后左右）滚屏
- 用行号或百分比作为书签浏览文件
- 实现了复杂检索，高亮显示等操作
- 阅读到文件结束不会退出

`head`：显示文件前几行

- 默认显示前十行

`tail`：显示文件后几行

- `-f`：显示正在改变的日志文件（`ctr+c`结束）

**重点用于追踪查看日志**：`tail -f a.log`  

#### 清空文件内容

在类Unix系统中，`/dev/null`称为空设备，是一个特殊的设备文件

- 它会丢弃一切写入其中的数据（但报告写入操作成功），读取它则会得到一个`EOF`

```bash
# 清空/etc/test.txt文档内容
cat /dev/null > /etc/test.txt
```



## 链接

### 软链接

又叫**符号链接**，类似于快捷方式

**建立软链接**：`ln -s target linkName`

- 建立了一个`linkNmae`的符号链接，指向了`target`（即给`target`目录文件取了一个别名`linkName`），访问`linkName`就相当于访问`target`
- 可以是文件，也可以是目录
- `-s`即`soft`

**查看链接**：`ls -l linkName`

- 会显示`linkName -> target`

> 就像快捷方式，删除`linkName`不会影响到`target`，删除`target`则`linkName`依旧存在，但没有意义

### 硬链接

硬链接用于将两个独立的文件联系在一起

- 硬链接是直接引用，软链接只是通过名称进行引用

**建立硬链接**：`ln target linkName`

**查看链接**：`ls -l linkName`

- 不会显示`linkName -> target`，说明两者完全独立

建立硬链接的两者具有相同的内容，对其中一个改动，另一个也会随之变化



# Docker

Docker是一个**容器引擎**，是应用程序与系统之间的隔离层

- 通常**应用程序对安装的系统环境**会有要求，如果服务器很多，部署时系统环境的配置工作是非常繁琐的


- Docker让应用程序不必再关心主机环境，各个应用安装在Docker镜像里，**Docker引擎负责运行包裹了应用程序的docker镜像**

**Docker架构**：C-S架构

- **docker Client**：输入各种docker命令
- **docker Server**：有一个Daemon后台进程，负责和docker Client通信，操作容器

**系统沙箱**

- **虚拟机方案**
  - 需要Hypervisor实现**硬件资源虚拟化**，每个app都有独立的Guest OS
- **容器方案**（linux kernel）
  - **只有一个HostOS**，容器中的应用程序**直接使用实际物理机的硬件资源**

> Linux系统的虚拟化技术，为Docker提供了底层技术支撑

## 虚拟机VM和Docker的区别

**Docker容器不是虚拟机**

容器和虚拟机的主要区别是

- 容器提供了**基于进程的隔离**
- 虚拟机提供了**资源的完全隔离**

容器使用宿主操作系统的内核，而虚拟机使用独立的内核。Docker使用的是Linux容器（Linux Container, LXC），跟其宿主运行同样的操作系统，**多个容器之间是共用同一套操作系统资源的**

> 虚拟机的启动比容器慢很多，虚拟机可能要一分钟来启动，但是容器只需要几秒甚至不到一秒

## Docker如何实现资源隔离

Docker的资源隔离主要依赖Linux的Namespace技术和Cgroups技术

- 通过namespaces隔离了进程树，网络接口和挂载点，实现进程之间的通信
- 通过CGroups隔离了CPU，内存，磁盘I/O和网络带宽

### Namespace

Namespace是Linux提供的资源隔离机制，Namespace通过调用Linux内核的方法实现各种资源的隔离，包括

- 文件系统
- IPC
- 进程号
- 网络设备和端口
- 挂载点
- 用户用户组

> 新创建的进程中各种类型的资源使用新的namespace，和主进程是隔离的

| 标题    | 系统调用参数  | 系统调用参数                           |
| ------- | ------------- | -------------------------------------- |
| UTS     | CLONE_NEWUTS  | 域名、主机名                           |
| IPC     | CLONE_NEWIPC  | 进程间通讯（用到的消息队列、共享内存） |
| PID     | CLONE_NEWPID  | 进程ID                                 |
| Network | CLONE_NEWNET  | 网络设备、网络栈、端口                 |
| Mount   | CLONE_NEWNS   | 挂载点                                 |
| User    | CLONE_NEWUSER | 用户用户组                             |

### Cgroups

Cgroups（Control groups）是Linux内核提供的资源限制和隔离的机制，Cgroups为每种可以控制的资源定义了一个子系统，包括

- cpu：限制可以使用的cpu使用率
- cpuset：为进程单独分配cpu或者内存节点
- cpuacct：统计cgroups中的进程对cpu的使用报告
- memory：限制内存的使用
- blkio：限制进程的块设备IO
- devices：控制进程能够访问哪些设备
- freezer：挂起或者恢复Cgroups中的进程
- net_cls：标记cgroups进程的网络数据包，通过traffic control对数据包进行流量控制
- net_prio：限制进程网络流量的优先级
- ns：控制cgroups中的进程使用不同的namespace

**Docker调用Cgroups的接口实现了不同容器对物理资源的控制**

## Docker文件系统

1. 宿主机上多个容器运行相同的系统，这些**系统里大部分文件内容都是相同的**
2. 为了节省资源，**将相同的内容和不同的内容隔开，分成只读层和可写层**
3. 然后就可以挂载同一个只读层，再挂载不同的可写层上
   1. 只读层（相同）：镜像
   2. 可写层（不同）：容器



# 数据结构

## 树

**应用场景**

- xml，html等的解析器
- 文件系统的目录结构
  - 文件目录树的起点是根目录
  - Linux文件系统中每一个文件在此目录树中的文件名都是独一无二的，因为其包含从根目录开始的完整路径
- MySQL数据库索引
  - B+树
- 路由协议
  - STP生成树协议，确保网络中没有环路
  - SPF最优树协议，确保网络中没有环路，还保障网络路径最优（网络路径代价最小）
- 数据文件压缩
  - 哈夫曼树广泛地用于数据文件压缩，十分有效的编码方法
- linux中进程的调度
  - 红黑树

## 链表

- Linux文件系统
  - 索引链接磁盘
- Git
  - 每次commit都是创建一个node，node包含了删减后的新文件，然后node指向前一个commit的node
- C语言标准库中`malloc()`函数
  - 内存块的分布是离散的，将各个内存块以链表的形式连接，组成空闲链表
  - 在用户使用`malloc()`函数申请内存时，遍历链表找到一个足够大的，能够满足用户需求的用户的大内存快，将它划分出一个与用户申请的内存相同大小的块，返回块地址
- 数据库
  - 字典使用用链表来解决冲突

### 数组和链表的区别

### Java中数组和链表的实现

# 设计模式

## 单例模式

单例模式是指**在内存中只会创建且仅创建一次对象的设计模式**

- 确保**某个类只有一个实例**

- 在程序中多次使用同一个对象且作用相同时，为了**防止频繁地创建对象使得内存飙升**
- 单例模式可以让程序仅在内存中创建一个对象，**让所有需要调用的地方都共享这一单例对象**

**单例模式类型**

- 饿汉式：在**类加载**时已经创建好该单例对象，等待被程序使用
- 懒汉式：在**真正需要使用**对象时才去创建该单例类对象

### 饿汉式

饿汉式**在类加载时已经创建好对象**，在程序**调用时直接返回该单例对象**

- **类加载时会在堆内存中创建一个对象**，当类消亡时对象也随之消亡了
- 如果对内存要求不高使用饿汉式，简单不易出错，且**没有任何并发安全和性能问题**
  - 如果从未使用过这个实例，会造成内存的浪费

```java
public class Singleton{
    
    private static final Singleton singleton = new Singleton();
    private Singleton(){}
    
    public static Singleton getInstance() {
        return singleton;
    }
}
```

### 懒汉式

懒汉式创建对象的方法是**在程序使用对象前先判断该对象是否已经实例化**（判空），若已实例化直接返回该类对象，**否则执行实例化操作再返回**

- 核心方法**不加锁会存在线程安全问题**

```java
public class Singleton {
    private static Singleton singleton;
    private Singleton(){}
    // 线程不安全
    public static Singleton getInstance() {
        if (singleton == null) {
            singleton = new Singleton();
        }
        return singleton;
    }
}
```

**加锁**

- 同步方法
  - 加锁后**每次去获取对象都需要先获取锁，并发性能非常地差**
  - 而且其实创建的方法只需要执行一次，后面直接返回对象即可
- 同步代码块
  - **双重检查**（Double-Check）
  - 线程安全，延迟加载，效率较高

```java
// 加锁，同步方法
public static synchronized Singleton getInstance() {
    if (singleton == null) {
        singleton = new Singleton();
    }
    return singleton;
}

// 加锁，同步代码块
public static Singleton getInstance() {
    if (singleton == null) {
        synchronized(Singleton.class) {
            // 再次判断，防止多个线程同时进入上一个null判断
            if(singleton == null) {
                singleton = new Singleton();
            }
        }
    }
    return singleton;
}
```

**优化性能**

- 如果没有实例化对象，则**加锁创建对象**
- 如果已经实例化了，则**不需要再获取锁而是直接获取实例**

> 需要两次判空，且对类对象加锁

```java
public class Singleton {
    
    private static Singleton singleton;
    private Singleton(){}
    
    public static Singleton getInstance() {
        if (singleton == null) {
            // 线程获得锁才可以进行实例化
            synchronized(Singleton.class) { 
                if (singleton == null) { 
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
```

#### 指令重排

JVM在保证最终结果正确的情况下，**可以不按照程序编码的顺序执行语句，尽可能提高程序的性能**

- 使用`volatile`关键字修饰的变量，**可以保证其指令执行的顺序与程序指明的顺序一致**，不会发生顺序变换


- `volatile`的作用仅仅是使用内存屏障来阻止指令重排序，**不涉及可见性问题**，可见性已经由`synchronized`来保证
- `synchronized`也有阻止重排序的功能，但是由monitor实现，**monitorenter和monitorexit之间的指令仍可能被重排序**，所以是不能保证指令重排的

  - **synchronized**的有序性是指持有相同锁的两个同步块只能串行的进入，即被加锁的内容要被多个线程有序执行，但是其**内部的同步代码还是会发生重排序**（这里就是对象的创建）


**指令重排下的创建**

- 如果JVM在分配好内存后，由于指令重排序**先将内存地址赋值给了对象变量，再去初始化内存区域**，则前一步的时候对象就已经非空，那么并发线程就会直接返回当前的对象，但这个对象是没有完成初始化的
- 即有`synchronized`无`volatile`的DCL双重检查锁单例，线程可能看到引用的当前值，但对象的状态值是失效的

```java
public class Singleton {
    
    // 防止指令重排
    private static volatile Singleton singleton;
    private Singleton(){}
    
    public static Singleton getInstance() {
        if (singleton == null) {
            // 线程获得锁才可以进行实例化
            synchronized(Singleton.class) { 
                if (singleton == null) { 
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
```

## 工厂模式



# 数据库

## SQL和NoSQL

- SQL数据库是关系型的，NoSQL是非关系型的
- SQL数据库使用结构化查询语言并具有**预定义的架构**，NoSQL数据库具有用于非结构化数据的动态架构
- SQL数据库是基于表的，而NoSQL数据库是文档，键值，图形或宽列存储
- SQL数据库更适合用于多行事务，NoSQL则适合于非结构化数据，例如文档或JSON

### Nosql

- NoSQL是为了解决Object-Oriented Database，Big Data和Distributed Database这三个在关系型数据库难以应付的硬骨头
- 典型的NoSQL数据库大概可以分成四类：键值数据库、文档数据库、列族数据库和图数据库

#### 键值数据库

**Redis**

- 可以把键值数据库看成一个简单的哈希表，主要用在所有数据库都通过主键来访问的情况下使用

- Key用来定位Value，Value对数据库而言是透明不可见的，不能对Value进行索引和查询，只能对Key进行查询，Value可以用来存储任意类型的数据，比如整型、字符型、数组，还可以是对象

**使用场景**

- **键值数据库比较适合存在大量写操作的场景**，比如内容缓存（会话、参数、购物车等）
  - 因为相对于关系型数据库而言，**关系型数据库需要通过建立索引来实现加速查询**，频繁发生写操作时，索引会发生频繁更新，因此产生维护索引的开销很大

- 并且关系数据库很难实现横向扩展而只能通过纵向扩展的方式实现扩充，但是键值数据库是天生具有良好的伸缩性，理论上可以通过横向扩展实现
- **键值数据库的弱项是条件查询**，如果只对部分值进行查询或者更新，键值数据库的效率比较低
- **键值数据库不支持回滚操作，所以无法支持事务**

#### 文档数据库

**MongoDB**

- 文档数据库中的文档和传统意义的文档没什么关系，**这里的文档其实是一个数据记录**，这个记录能够对包含的数据类型和内容进行自我描述
  - XML文档、HTML文档和JSON文档就属于这一类
- 文档数据库可以包含非常复杂的数据结构，比如嵌套对象并且不需要使用特定的数据模式，**每个文档可以具有完全不同的结构**
- 文档数据库可以看做是键值数据库的升级版，**而且它比键值数据库具有更高的查询效率**
  - 与键值数据库不同，文档数据库既可以根据Key来构建索引，也可以基于文档内容来构建索引
- 传统的关系数据库的存储方式是以表的形式存放，MongoDB中则以文档的形式存在，数据结构由键值对组成
  - MongoDB文档类似于JSON对象，字段值可以包含其他文档，数组及文档数组

**应用场景**

- 应用服务器的日志记录，查找起来比文本灵活，导出也很方便
  - MongoDB的格式灵活，不用为了各种格式不一样的信息专门设计统一的格式，增加字段不用改表结构

> 这个场景mysql也能解决，没必要一定用MongoDB。的确，并没有某个业务场景必须要使用MongoDB才能解决，但使用MongoDB通常能让你以更低的成本解决问题（包括学习、开发、运维等成本）

## MySQL

### 三种日志的区别和作用

- undo log：回滚记录到某个特定版本，通常是逻辑日志，根据每行记录进行记录
- redo log：恢复提交事务修改的页操作，通常是物理日志，记录的是页的物理修改操作
- bin log：用来进行Point-In-Time(PIT)的恢复及主从复制环境的建立

#### bin log和redo log的区别

- redo log是在InnoDB存储引擎层产生的
- bin log是在MySQL数据库上层产生的，不仅仅针对InnoDB存储引擎，任何存储引擎都会产生bin log

bin log和redo log记录内容形式不同
- bin log是一种逻辑日志，记录的是SQL语句
- InnoDB存储引擎层面的redo log是物理格式日志，记录的是对于每个页的修改

bin log和redo log写入磁盘的时间不同
- bin log只在事务提交完成后进行一次写入
- redo log在事务进行中不断的写入


### 创建索引

三种方式

- `CREATE INDEX`
  - `CREATE INDEX indexName ON tableName (columnName(length));`
- `ALTER`
  - `ALTER TABLE tableName ADD INDEX indexName(columnName);`
- 创建表时创建索引

### Innodb和MyIsam的区别

1. innodb支持事务，myisam不支持
2. MyISAM适合查询以及插入为主的应用，InnoDB适合频繁修改以及涉及到安全性较高的应用
3. innodb支持外键，myisam不支持
4. innodb需要扫描表来计算有多少行，myisam不需要
5. 对于自增长字段，innodb必须包含只含有该列的索引，myisam可以和其他一起组成联合索引
6. innodb支持行锁，myisam不支持



### 联结

`join`：一种机制

- 在一条select语句中关联不同的表，关联不同表中的行（一个表中的行和另一个表中的行相关联）

#### 创建联结

**笛卡尔积**

- 联结两个表时，实际上是**拿第一个表的每一行和第二个表的每一行对比**，所以如果不通过`where`子句过滤某些row，就会返回所有的行（n*m）
- 有一些组合是根本不存在的，即会组合出错误的数据返回，所以联结必须要有`where`子句进行过滤

### 外部联结

`outer join`

- 包含了相关表中没有关联行的行
- 必须使用`left`和`right`来指定包括其所有col的表
  - `left`：指`outer join`左边的表
  - `right`：指`outer join`右边的表

**区别**

- `left join`：返回包括**左表中的所有记录**和**右表中联结字段相等的记录**
- `right join`：返回包括**右表中的所有记录**和**左表中联结字段相等的记录**

> left就是左表的记录将会全部表示出来，而右表只会显示符合搜索条件的记录

### MySQL底层索引结构

- InnoDB里面的B+Tree？

- B Tree和B+ Tree的区别
- MySQL索引的发展过程？
  - 是一来就是B+Tree的么？从没有索引、hash、二叉排序树、AVL树、B树、B+树聊
- MySQL中如果使用like进行模糊匹配的时候，是否会使用索引？一定不会用么？

###  事务

**事务指的是满足ACID特性的一组操作**

- 一个数据库事务通常包含了一个序列的对数据库的读写操作

### 事务隔离级别

MySQL支持四种事务隔离级别

#### 读取未提交

`READ UNCOMMITTED`

- **事务中的修改即使没有提交，对其它事务也是可见的**，允许其他事务读取未提交的修改
- **可能会导致脏读，幻读和不可重复读**

#### 读取已提交

`READ COMMITTED`

- **一个事务只能读取已经提交的事务所做的修改**，
- 可以防止脏读
- **可能会导致不可重复读和幻读**

#### 可重复读

`REPEATABLE READ`

- **保证在同一个事务中多次读取同一数据的结果是一样的**
- 可以防止脏读和不可重复读
- **可能会导致幻读**

#### 可串行化

`SERIALIZABLE`

- **强制事务串行执行**，要使用加锁机制保证事务串行执行


- **可以防止脏读，不可重复读和幻读**

> 多个事务互不干扰，不会出现并发一致性问题

### 可重复读和幻读的区别

> 数据库的命令的执行者的封装基本抽象是Transaction，SQL语句的执行都会有对应的Transaction对象，并且都会有对应的id来标识不同的Transaction，Transaction id按照不同的时序来分配，执行一个简单的autocommit类型的语句都会对应生成一个新的Transaction，transaction id的大小可以表示SQL语句执行发生的早晚
>
> MySQL的表中的一个存储的数据行会有多个版本快照，每个版本快照都会对应一个transaction id，当一个数据行的数据被某个transaction更新时，这个行就会有一个hidden column记录了这个更新事务的transaction id，旧数据在被覆盖的之前会存储到Undo Log日志文件中，Undo Log通过回滚指针`ROLL_PTR`把一个数据行的所有版本快照链接起来

#### 可重复读

在事务中如果执行一条普通的`select`语句（非`select for update`语句），根据条件会找到一些满足的数据行记录

- **如果是读取已提交的隔离模式**
  - 每次查询只需要返回满足条件的最新的行记录即可，此时就不可重复读
- **如果是可重复读的隔离模式**
  - 对于每个匹配的行记录，要从Undo Log中找到对应的最近一次执行更新操作的transaction id
  - 将这个transaction id和当前事务的transaction id进行比较
    - 如果大于当前事务的transaction id，那么就需要去Undo Log中去寻找旧版本的快照，一直找到小于当前transaction id的行记录的版本快照，将其作为查询数据返回
  - 所以即使在当前这个事务执行过程中，有其它事务执行插入了新的数据并且能够满足查询条件，但因为这个数据对应的事务的transaction id大于当前查询事务的transaction id，是查询不到新数据的

> 可重复读每次读取的都是数据的相同版本的快照

#### 幻读

对于`select for update`语句，两次查询到了不同的数据

- 从情理上来看是很正常的，因为数据库是一个支持大量并发任务的服务，在事务执行的过程中，新的数据插入是很正常的事情，这不是BUG

所以需要加锁，但是不能只对满足条件的行数据加锁，因为查询可能是一个范围

- 比如查询`a>5 and a<10`，目前只有一条记录`a=7`，如果只锁`a=7`这个记录，而其它事务可能还会做新的插入操作，比如插入一条`a=9`的记录
- 假如业务逻辑是如果当前a在`[5,10]`的区间中只有一条记录就可以删除这个记录，在上一次查询的时候是只有一条行记录，满足条件，但现在要删除这个记录，却发现`[5,10]`中有了2条记录，那么此时的删除操作就是错误的操作

所以数据库引入了间隙锁（gap lock），对这个区间都加锁，而不仅仅是已有的行记录

- 这时当前事务就独占了这个区间，其它的事务在处理过程中就无法插入新的数据



### MySQL慢查询

**三个问题**

1. 索引建立的合适吗？查询有没有用到索引
2. 长事务多，查询语句复杂，表连接操作过多，查询时间长，简化查询语句
3. 高频数据可以考虑放在redis之类的缓存中，不再通过数据库

Mysql中提供了对应的工具，只需要开启对应的**慢查询日志**功能，然后配置即可

Mysql会把查询时间大于设置时间的SQL记录下来，并且保存到一个专门的文件中

```bash
# 开启或关闭慢查询日志
slow_query_log = ON
# 指定生成的慢查询日志路径（未设置则和默认和数据文件放一起）
slow_query_log_file = /opt/soft/mysql/log/slow.log
# 慢查询记录时间阈值，SQL执行超过此时间则会被记录到日志（单位：秒，默认10秒）
long_query_time = 5
# 是否记录未使用索引的SQL
log_queries_not_using_indexes=on
```

#### 查询慢查询数量

- 一般来说正常运行的MySQL服务器**每分钟的慢查询在个位数是正常的**，接近100系统可能就有问题了

- **慢查询的数量保存在mysql库里面的`slow_log`表**

#### 查看当前进行的查询状态

- `show processlist`
  - **查看当前系统中正在执行的查询**
- 这些数据也保存在`information_schema`库里面的`processlist`表
  - 如果要做条件查询，直接查询这张表更方便
- 可以已经执行时间**倒排**

#### 系统问题和定位

- 分析到底是哪些查询为什么会引发系统阻塞，使用慢查询来做分析
- 慢查询表**查询结果**中有几个比较重要的指标
- `start_time`：开始时间，通过这个参数联系系统出问题的时间定位哪些查询是问题根源
- `query_time` ：查询时间
- `rows_sent / rows_examined`：**发送的结果数和查询扫过的行数**
  - `rows_examined`基本上能突出哪个查询是需要注意的**大查询**

> 实际操作中，也是把有大量`rows_examined`的查询一个个拿出来分析，添加索引，修改查询语句的编写，来彻底解决问题

### 主从复制的流程

## 数据库和缓存数据一致性

数据库与缓存数据一致解决方式中的2个问题

- 先操作数据库后缓存还是先缓存后操作数据库
- 缓存是更新还是删除

**操作的先后顺序**

- 在并发系统中，**数据库与缓存双写场景下**，为了追求更大的并发量，操作数据库与缓存显而易见不会同步进行
- **一般前者操作成功，后者以异步的方式进行**
  - 从数据安全的角度来讲，先操作数据库，然后以异步的方式操作缓存，响应用户请求

- 关系型数据库作为成熟的工业级数据存储方案，有完善的事务处理机制，数据一旦落盘，不考虑硬件故障可以负责任的说数据不会丢失

缓存是存储在内存中的数据，服务一旦重启，缓存数据全部丢失

- 要时刻做好了缓存数据丢失的准备，尽管Redis有持久化机制，也不能够保证百分之百持久化

- 缓存是缓存，数据库是数据库，两个不同的东西，把缓存当数据库使用是一件极其危险的事情

**如何处理缓存**

- **缓存是更新还是删除，对应懒汉式和饱汉式**
- 从线程安全来讲，删除缓存操作相对难度低一些，如果在删除缓存的前提下满足了查询性能，那么优先选择删除缓存

- 更新缓存尽管能够提高查询效率，然后带来的线程并发脏数据处理起来较麻烦，非必要不推荐

### 并发分析

**非并发环境**

- 先查询缓存，如果缓存数据不存在，查询数据库
- 然后更新缓存，返回结果

> 如果在高并发环境中：当缓存失效时，大量查询请求涌入，瞬间全部打到DB上，轻则数据库连接资源耗尽，用户端响应500错误，重则数据库压力过大服务宕机

```java
public BuOrder getOrder(Long orderId) {
    String key = ORDER_KEY_PREFIX + orderId;
    BuOrder buOrder = RedisUtils.getObject(key, BuOrder.class);
    if (buOrder != null) {
        return buOrder;
    }
    BuOrder order = getById(orderId);
    RedisUtils.setObject(key, order, 5, TimeUnit.MINUTES);
    return order;
}
```

**并发环境**

- **使用分布式锁**
  - 当大量请求涌入时，**获得锁的线程有机会访问数据库查询数据**，其余线程阻塞
- 当查询完数据并更新缓存后才释放锁，等待的线程重新检查缓存，发现能够获取到数据，直接将缓存数据响应

**分布式锁使用表锁还是行锁**

- 使用分布式**行锁提高并发量**
- 使用二次检查机制，确保等待获得锁的线程能够快速返回结果

```java
@Override
public BuOrder getOrder(Long orderId) {
    String key = ORDER_KEY_PREFIX + orderId;
    BuOrder order = RedisUtils.getObject(key, BuOrder.class);
    if (order != null) {
        return order;
    }
    // 如果缓存不存在，则添加分布式锁更新缓存
    String orderLock = ORDER_LOCK + orderId;
    RLock lock = redissonClient.getLock(orderLock);
    if (lock.tryLock()) {
        order = RedisUtils.getObject(key, BuOrder.class);
        // 二次检查
        if (order != null) {
            LockOptional.ofNullable(lock).ifLocked(RLock::unlock);
            return order;
        }
        BuOrder buOrder = getById(orderId);
        RedisUtils.setObject(key, buOrder, 5, TimeUnit.MINUTES);
        LockOptional.ofNullable(lock).ifLocked(RLock::unlock);
    }
    return RedisUtils.getObject(key, BuOrder.class);
}
```

### 更新数据

**非并发环境**

- 使用数据库层面的**乐观锁**能够解决数据被覆盖问题，然而无效更新流量依旧会流向数据库
- 当同一行记录被修改后，版本号发生改变，后续并发流向数据库的请求为无效流量

```java
// 可能会产生数据不一致问题（数据被覆盖）
public Boolean editOrder(BuOrder order) {
    /* 更新数据库 */
    updateById(order);
    /* 删除缓存 */
    RedisUtils.deleteObject(OrderServiceImpl.ORDER_KEY_PREFIX + order.getOrderId());
    return true;
}
```

**并发环境**

- 减小数据库压力的首要策略是将无效流量拦截在数据库之前

- **使用分布式锁能够保证并发流量有序访问数据库**，考虑到数据库层面已经使用了乐观锁，第二个及以后获得锁的线程操作数据库为无效流量

- 线程在获得锁时采用**超时退出**的策略，等待获得锁的线程超时快速退出，快速响应用户请求，重试更新数据操作

```java
public Boolean editOrder(BuOrder order) {
    String orderLock = ORDER_LOCK + order.getOrderId();
    RLock lock = redissonClient.getLock(orderLock);
    try {
        /* 超时未获取到锁，快速失败，用户端重试 */
        if (lock.tryLock(1, TimeUnit.SECONDS)) {
            /* 更新数据库 */
            updateById(order);
            /* 删除缓存 */
            RedisUtils.deleteObject(OrderServiceImpl.ORDER_KEY_PREFIX + order.getOrderId());
            /* 释放锁 */
            LockOptional.ofNullable(lock).ifLocked(RLock::unlock);
            return true;
        }
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
    return false;
}
```

### 更新顺序

**先更新数据库，后删除缓存存在并发问题**

- 缓存刚好失效
- 请求A查询数据库，得一个旧值
- 请求B将新值写入数据库
- 请求B删除缓存
- 请求A将查到的旧值写入缓存

**解决方式**

- **增加缓存过期时间**
  - 增加缓存过期时间**允许一定时间范围内脏数据存在**（直到下一次并发更新）
  - 脏数据会周期性存在
- **更新和查询共用一把行锁**
  - 更新和查询共用一把行分布式锁
  - 当读请求获取到锁时，写请求处于阻塞状态（超时会快速失败返回）
- **延迟删除缓存**
  - 使用RabbitMQ延迟删除缓存，使用异步的方式进行，几乎不影响性能
  - 在操作数据库前，向RabbitMQ写入一条延迟删除缓存的消息，然后执行数据库操作，执行缓存删除操作
  - 不管代码层面缓存是否删除成功，MQ删除缓存作为保底操作

## 一致性Hash算法

一致性Hash算法是**解决分布式缓存等问题**的一种算法

**背景**

1. 有三台缓存服务器编号n1，n2，n3
2. 有1000w个key，希望可以将这些个key均匀的缓存到三台机器上
3. 取模算法：对key进行hash运算后取模
   1. `hash(key) % N`，N是机器数量

**问题**

- 对机器数量取模，在集群扩容和收缩时却有一定的局限性，**因为在生产环境中根据业务量的大小，调整服务器数量是常有的事**
- **当其中一个服务器节点挂了**，取模的结果就会发生变化，key的缓存位置大概率会发生改变，之前缓存key的数据也会失去作用与意义
- 大量缓存在同一时间失效，造成**缓存的雪崩**，进而导致整个缓存系统的不可用

### 算法详解

一致性hash算法对**固定值`2^32`取模**：`hash(key)% 2^32`

> IPv4的地址是32位2进制数组成，所以用`2^32`可以保证每个IP地址会有唯一的映射

一致性哈希算法在1997年由麻省理工学院提出，是一种特殊的哈希算法

- **在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系**
- 一致性哈希解决了简单哈希算法在**分布式哈希表**（Distributed Hash Table，DHT）中存在的动态伸缩等问题

### Hash环

- 将`2^32`个值抽象成一个圆环，1、2直到`2^32-1`，这个圆环称为**hash环**
- **每个服务器都会映射在hash环上的一个位置，每个key也都会映射在hash环上的一个位置**
- 从缓存对象key的位置开始，**沿顺时针方向遇到的第一个服务器**，便是当前对象将要缓存到的服务器

所以一致性Hash就是：**将原本单个点的Hash映射，转变为了在一个环上的某个片段上的映射**

> 当动态扩缩容服务器时只有少部分对象需要重新分配

### 数据倾斜

实际场景中很难选取到一个Hash函数这么完美的将各个服务器散列到Hash环上

- 在服务器节点数量太少的情况下，很容易因为**节点分布不均匀而造成数据倾斜问题**
- 被缓存的对象大部分缓存在某一个服务器上，导致其他节点资源浪费，系统压力大部分集中在这个服务器上，这样的集群是非常不健康的
- 新增服务器时也可能不会分担之前的压力

### 虚拟节点

通过引入**虚拟节点**来解决负载不均衡的问题

- **将每台物理服务器虚拟为一组虚拟服务器**
- 将虚拟服务器放置到哈希环上
- 如果要确定对象的服务器，需要先确定对象的虚拟服务器，**再由虚拟服务器确定物理服务器**

即增加一层虚拟节点到物理节点的映射

> 分配的虚拟节点个数越多，映射在hash环上才会越趋于均匀，节点太少的话很难看出效果

**虚拟节点的Hash计算**

通常采用：节点的IP地址 + 数字编号后缀（10.24.23.227#1）

**问题**

- 引入虚拟节点的同时也增加了新的问题，要做虚拟节点和真实节点间的映射
- 即`对象key->虚拟节点->实际节点`之间的转换
